{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# James Cooper\n",
    "# Assignment 2\n",
    "# CSC 478-710"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##        Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\James Cooper\\\\Desktop\\\\DePaul\\\\Programming Machine Learning\\\\Assignment2'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\James Cooper\\\\Desktop\\\\DePaul\\\\Programming Machine Learning\\\\Assignment2'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"C:\\Users\\James Cooper\\Desktop\\DePaul\\Programming Machine Learning\\Assignment2\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Create your own KNN classifier function. Your classifier should allow as input the training data matrix, the training labels, the instance to be classified, the value of K, and should return the predicted class for the instance and the top K neighbors. Your classifier should work with Euclidean distance as well as Cosine Similarity. You may create two separate classifiers, or add this capability as a parameter for the classifier function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainmatrix = pd.read_csv(\"trainMatrixModified.txt\",delimiter=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>790</th>\n",
       "      <th>791</th>\n",
       "      <th>792</th>\n",
       "      <th>793</th>\n",
       "      <th>794</th>\n",
       "      <th>795</th>\n",
       "      <th>796</th>\n",
       "      <th>797</th>\n",
       "      <th>798</th>\n",
       "      <th>799</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   790  791  792  793  \\\n",
       "0  2.0  0.0  0.0  2.0  2.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "1  2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  3.0  0.0   \n",
       "2  2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "3  1.0  1.0  1.0  1.0  1.0  1.0  2.0  1.0  1.0  1.0 ...   1.0  1.0  1.0  1.0   \n",
       "4  8.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  2.0  0.0   \n",
       "\n",
       "   794  795  796  797  798  799  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "\n",
       "[5 rows x 800 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matrix is in termxdocument\n",
    "trainmatrix.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of terms =  5500\n",
      "Number of docs =  800\n"
     ]
    }
   ],
   "source": [
    "#0 = rows\n",
    "#1 = columns\n",
    "numterms=trainmatrix.shape[0]\n",
    "numdocs=trainmatrix.shape[1]\n",
    "print \"Number of terms = \", numterms\n",
    "print \"Number of docs = \", numdocs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5490</th>\n",
       "      <th>5491</th>\n",
       "      <th>5492</th>\n",
       "      <th>5493</th>\n",
       "      <th>5494</th>\n",
       "      <th>5495</th>\n",
       "      <th>5496</th>\n",
       "      <th>5497</th>\n",
       "      <th>5498</th>\n",
       "      <th>5499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...   5490  \\\n",
       "0   2.0   2.0   2.0   1.0   8.0   6.0   2.0   8.0   2.0   4.0  ...    0.0   \n",
       "1   0.0   0.0   0.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "2   0.0   0.0   0.0   1.0   0.0   0.0   0.0   2.0   0.0   1.0  ...    0.0   \n",
       "3   2.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "4   2.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   \n",
       "\n",
       "   5491  5492  5493  5494  5495  5496  5497  5498  5499  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 5500 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainmatrix_pdtr = trainmatrix.T\n",
    "trainmatrix_pdtr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transpose to docxterm matrix\n",
    "trainmatrix_Tr = np.array(trainmatrix.T, dtype = int)\n",
    "trainmatrix_Tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainmatrix_Tr2 = np.array(trainmatrix.T, np.int64)\n",
    "trainmatrix_Tr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800L, 5500L)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainmatrix_Tr2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "5500\n"
     ]
    }
   ],
   "source": [
    "numdocs_T = trainmatrix_Tr2.shape[0]\n",
    "numterms_T = trainmatrix_Tr2.shape[1]\n",
    "print numdocs_T\n",
    "print numterms_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1\n",
       "0  0\n",
       "1  1\n",
       "2  0\n",
       "3  1\n",
       "4  0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the classes for the data: 0 = Microsoft, 1 = Hockey\n",
    "trainlabels = pd.read_csv(\"trainClasses.txt\",delimiter=\"\\t\", header=None)\n",
    "trainlabels_ix = trainlabels.iloc[:,1:]\n",
    "trainlabels_ix.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Turn class labels into a numpy array\n",
    "trainlabelarray = np.array(trainlabels_ix)\n",
    "trainlabelarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       102\n",
      "1        11\n",
      "2        22\n",
      "3       959\n",
      "4       222\n",
      "5        84\n",
      "6       108\n",
      "7       262\n",
      "8        55\n",
      "9       318\n",
      "10       69\n",
      "11       41\n",
      "12      148\n",
      "13      128\n",
      "14      128\n",
      "15      146\n",
      "16      201\n",
      "17       39\n",
      "18      159\n",
      "19        6\n",
      "20      189\n",
      "21       65\n",
      "22      227\n",
      "23       89\n",
      "24       40\n",
      "25      329\n",
      "26       43\n",
      "27       18\n",
      "28       54\n",
      "29        8\n",
      "       ... \n",
      "5470      3\n",
      "5471      4\n",
      "5472      3\n",
      "5473      3\n",
      "5474      3\n",
      "5475      3\n",
      "5476      3\n",
      "5477      3\n",
      "5478      2\n",
      "5479      4\n",
      "5480      3\n",
      "5481      2\n",
      "5482      3\n",
      "5483      3\n",
      "5484      5\n",
      "5485      4\n",
      "5486      3\n",
      "5487      2\n",
      "5488      2\n",
      "5489      2\n",
      "5490      3\n",
      "5491      2\n",
      "5492      1\n",
      "5493      2\n",
      "5494      3\n",
      "5495      3\n",
      "5496      3\n",
      "5497      2\n",
      "5498      2\n",
      "5499      2\n",
      "Length: 5500, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Using the untransposed matrix (trainmatrix) to count the frequency of terms by document (count by columns)\n",
    "freqbyterm = trainmatrix.sum(axis=1)\n",
    "freqbyterm_int = freqbyterm.astype(np.int64)\n",
    "print freqbyterm_int\n",
    "freqbyterm.to_csv('freqbyterm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                       david\n",
      "1                         rex\n",
      "2                        wood\n",
      "3                     subject\n",
      "4                        call\n",
      "5                     librari\n",
      "6                       creat\n",
      "7                      widget\n",
      "8                     multipl\n",
      "9                        time\n",
      "10                        dai\n",
      "11                        ago\n",
      "12                       post\n",
      "13                   question\n",
      "14                        try\n",
      "15                   function\n",
      "16                        set\n",
      "17                        app\n",
      "18                      point\n",
      "19                 xtappiniti\n",
      "20                       help\n",
      "21                       have\n",
      "22                    problem\n",
      "23                      littl\n",
      "24                       test\n",
      "25                    program\n",
      "26                      close\n",
      "27                      model\n",
      "28                       real\n",
      "29                     actual\n",
      "                ...          \n",
      "5470                 director\n",
      "5471                  overlap\n",
      "5472                    twmrc\n",
      "5473                     ctwm\n",
      "5474                    utter\n",
      "5475                  leunggm\n",
      "5476    odincontrolutorontoca\n",
      "5477                    leung\n",
      "5478                  reclaim\n",
      "5479                     cach\n",
      "5480                   sussex\n",
      "5481                    newli\n",
      "5482                xtgetvalu\n",
      "5483                     fuer\n",
      "5484    xtcreatemanagedwidget\n",
      "5485                   fulton\n",
      "5486                  attende\n",
      "5487                     cose\n",
      "5488                     icop\n",
      "5489                 csabuedu\n",
      "5490                  antonio\n",
      "5491                     pera\n",
      "5492              undoubtedli\n",
      "5493                 shortcut\n",
      "5494                      ear\n",
      "5495                    shear\n",
      "5496                    handi\n",
      "5497              inexperienc\n",
      "5498                    markw\n",
      "5499          pspmf3gpsemicom\n",
      "Name: 0, Length: 5500, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Import the terms file\n",
    "terms = pd.read_csv(\"modifiedterms.txt\", header=None)\n",
    "terms2 = terms.iloc[:,0]\n",
    "print terms2\n",
    "terms2.to_csv('terms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('00', 102), ('000', 34), ('01', 30), ('02', 28), ('0223', 7), ('0228', 2), ('03', 29), ('04', 26), ('0444', 5), ('05', 18), ('06', 23), ('07', 23), ('08', 14), ('09', 14), ('0ha', 3), ('0xff', 2), ('10', 249), ('100', 52), ('1000', 10), ('10000', 3), ('1006', 5), ('1008', 7), ('101', 18), ('1010', 3), ('1017', 5), ('1018', 3), ('1019', 2), ('102', 15), ('1020', 8), ('1021', 3), ('1024', 3), ('103', 16), ('1033', 5), ('1038', 4), ('104', 22), ('1040', 4), ('1043', 2), ('1046', 5), ('1049', 4), ('105', 14), ('10510', 3), ('1053', 4), ('1054', 5), ('1057', 3), ('106', 12), ('1062', 3), ('1063', 3), ('1067', 3), ('107', 8), ('1071', 4), ('1072', 3), ('1076', 4), ('108', 12), ('1082', 5), ('109', 8), ('1096', 3), ('10th', 3), ('10x20', 3), ('11', 178), ('110', 23), ('1109', 3), ('111', 21), ('11150', 4), ('112', 17), ('1120', 3), ('1121', 5), ('1126', 3), ('113', 12), ('1136', 3), ('114', 13), ('1140', 5), ('1142', 3), ('1146', 5), ('1149', 4), ('115', 10), ('1156', 3), ('116', 13), ('117', 10), ('1174', 4), ('118', 11), ('1180', 7), ('11800', 3), ('119', 12), ('1193', 4), ('1196', 3), ('11th', 2), ('12', 128), ('120', 13), ('121', 14), ('1210', 3), ('122', 14), ('1229', 3), ('123', 12), ('124', 10), ('1242', 3), ('125', 14), ('126', 12), ('127', 19), ('128', 12), ('1280', 6), ('129', 11), ('13', 101), ('130', 12), ('131', 15), ('132', 15), ('13220611', 1), ('133', 12), ('134', 12), ('135', 9), ('136', 9), ('137', 9), ('138', 9), ('139', 15), ('14', 95), ('140', 14), ('1400', 3), ('141', 10), ('1416', 3), ('142', 16), ('1428', 3), ('143', 12), ('144', 19), ('145', 11), ('146', 10), ('146270226', 3), ('147', 10), ('148', 12), ('149', 11), ('15', 104), ('150', 18), ('151', 13), ('152', 11), ('152133890', 4), ('153', 8), ('1536', 3), ('154', 10), ('155', 9), ('156', 7), ('157', 14), ('158', 7), ('159', 10), ('16', 97), ('160', 14), ('161', 10), ('162', 7), ('163', 13), ('1636', 3), ('164', 8), ('1641', 3), ('1649', 3), ('165', 10), ('166', 6), ('167', 13), ('168', 13), ('1685', 3), ('169', 8), ('17', 85), ('170', 8), ('171', 14), ('172', 12), ('173', 6), ('174', 7), ('1748', 3), ('175', 7), ('176', 14), ('177', 9), ('178', 8), ('179', 8), ('1790', 3), ('18', 97), ('180', 10), ('181', 11), ('182', 8), ('183', 12), ('184', 11), ('185', 14), ('186', 8), ('187', 10), ('188', 6), ('1881', 2), ('189', 6), ('19', 89), ('190', 9), ('191', 6), ('192', 8), ('193', 7), ('194', 7), ('195', 8), ('196', 18), ('197', 7), ('198', 7), ('1980', 3), ('1984', 4), ('1985', 2), ('1986', 3), ('1987', 3), ('1988', 5), ('1989', 12), ('198990', 2), ('199', 8), ('1990', 22), ('1991', 18), ('1992', 34), ('199293', 8), ('1993', 82), ('1993apr200320175783', 4), ('1993apr202145056925', 3), ('1993apr212340222880', 3), ('1993apr23102811623', 2), ('1993may132123212563', 2), ('1994', 2), ('1call', 3), ('1r23on4p6', 3), ('1st', 46), ('1x', 3), ('20', 118), ('200', 23), ('2000', 10), ('201', 12), ('2016', 3), ('202', 11), ('203', 8), ('204', 6), ('205', 16), ('206', 9), ('207', 10), ('208', 12), ('209', 12), ('20th', 2), ('21', 83), ('210', 13), ('211', 9), ('212', 9), ('213', 17), ('214', 6), ('215', 13), ('216', 10), ('217', 9), ('218', 8), ('219', 7), ('22', 62), ('220', 11), ('221', 12), ('222', 9), ('223', 16), ('224', 9), ('225', 16), ('226', 8), ('227', 8), ('228', 8), ('229', 10), ('23', 61), ('230', 14), ('231', 11), ('232', 10), ('233', 16), ('234', 11), ('235', 7), ('236', 8), ('237', 7), ('238', 10), ('239', 9), ('24', 85), ('240', 17), ('241', 8), ('242', 10), ('243', 10), ('244', 6), ('245', 7), ('246', 7), ('247', 7), ('248', 10), ('249', 10), ('2493', 4), ('24bit', 12), ('25', 74), ('250', 17), ('2500', 2), ('251', 9), ('252', 7), ('253', 16), ('254', 10), ('255', 8), ('256', 28), ('257', 9), ('258', 11), ('259', 9), ('26', 56), ('260', 10), ('261', 6), ('262', 8), ('2630', 2), ('269', 8), ('27', 54), ('270', 2), ('271', 4), ('272', 3), ('273', 8), ('275', 5), ('2752527', 3), ('276', 3), ('28', 52), ('281', 4), ('282', 5), ('283', 6), ('284', 5), ('287', 2), ('288', 4), ('29', 53), ('290', 3), ('292', 4), ('29apr93', 3), ('2call', 3), ('2d', 7), ('2nd', 53), ('30', 157), ('300', 21), ('3000', 11), ('301', 7), ('302', 8), ('30th', 3), ('31', 96), ('310', 15), ('313', 2), ('314', 3), ('315', 2), ('316', 4), ('317', 4), ('318', 9), ('319', 2), ('32', 65), ('320', 8), ('321', 5), ('322', 4), ('323', 6), ('324', 9), ('33', 62), ('330', 7), ('337', 5), ('337523', 3), ('337548', 3), ('3387', 5), ('339', 7), ('34', 43), ('340', 4), ('344', 3), ('345', 6), ('346', 3), ('347', 4), ('348', 14), ('35', 52), ('350', 7), ('353', 6), ('356', 7), ('36', 34), ('367', 5), ('369', 5), ('37', 44), ('370', 3), ('37501', 3), ('376', 7), ('38', 47), ('382', 6), ('383', 4), ('384', 4), ('386', 40), ('386bsd', 6), ('39', 40), ('393', 5), ('394', 3), ('395', 3), ('396', 5), ('3961', 5), ('397', 4), ('3call', 3), ('3d', 14), ('3pt', 3), ('3rd', 52), ('40', 79), ('400', 13), ('4000', 4), ('401', 5), ('402', 6), ('403', 15), ('404', 2), ('407', 4), ('408', 25), ('41', 47), ('410', 3), ('411', 14), ('412', 13), ('413', 16), ('414', 5), ('415', 11), ('416', 9), ('42', 49), ('420', 5), ('421', 5), ('424', 7), ('429', 5), ('43', 48), ('430', 2), ('4324219', 11), ('434', 4), ('44', 69), ('440', 3), ('445', 4), ('449', 6), ('45', 37), ('451', 3), ('452', 6), ('458', 4), ('46', 23), ('460', 4), ('4612018', 3), ('4615001x431', 4), ('462', 5), ('4620666', 6), ('467', 3), ('468', 4), ('469', 9), ('47', 33), ('472', 7), ('4769', 3), ('479', 4), ('48', 32), ('480', 3), ('486', 29), ('488', 4), ('489', 4), ('49', 43), ('493', 5), ('498', 4), ('4b', 3), ('4th', 7), ('50', 85), ('500', 18), ('5000', 11), ('502', 5), ('503', 10), ('509', 8), ('51', 61), ('511', 4), ('512', 14), ('518', 3), ('52', 36), ('520', 7), ('524', 3), ('525', 3), ('526', 3), ('53', 34), ('5300', 2), ('532', 6), ('54', 34), ('542', 5), ('544', 7), ('548', 4), ('55', 25), ('554', 5), ('555', 4), ('559', 6), ('56', 31), ('563', 4), ('57', 31), ('5716', 3), ('573', 4), ('58', 22), ('580', 4), ('582', 4), ('59', 25), ('595', 3), ('5b', 4), ('5th', 2), ('5x', 3), ('60', 41), ('600', 3), ('6000', 20), ('602', 2), ('603', 10), ('604', 9), ('605', 5), ('61', 28), ('613', 3), ('614', 5), ('617', 5), ('619', 13), ('62', 21), ('621', 5), ('624', 2), ('63', 29), ('635', 3), ('637', 6), ('64', 17), ('640', 6), ('65', 27), ('653', 3), ('66', 25), ('660', 6), ('661', 3), ('666', 2), ('67', 15), ('68', 19), ('68000', 4), ('68020', 3), ('686', 4), ('69', 14), ('691', 6), ('70', 30), ('700', 9), ('7000', 3), ('701', 6), ('703', 3), ('705', 3), ('708', 5), ('71', 31), ('711', 2), ('713', 7), ('716', 10), ('72', 18), ('720', 3), ('725', 3), ('726', 3), ('727', 3), ('73', 23), ('730', 3), ('733', 3), ('738786', 2), ('74', 16), ('7486347', 2), ('749', 3), ('75', 22), ('750', 3), ('751', 4), ('76', 32), ('761', 4), ('763', 3), ('77', 26), ('777', 6), ('78', 22), ('780', 3), ('784', 5), ('79', 20), ('795', 3), ('796', 3), ('7th', 9), ('80', 36), ('800', 11), ('801', 5), ('804', 7), ('806', 4), ('807', 5), ('81', 25), ('816', 3), ('817', 6), ('818', 6), ('82', 22), ('823', 2), ('825', 7), ('83', 12), ('835', 4), ('836', 4), ('839', 4), ('84', 16), ('843', 2), ('848', 5), ('85', 24), ('850', 5), ('851', 4), ('856', 3), ('858', 4), ('86', 26), ('860', 3), ('861', 5), ('87', 23), ('871', 3), ('872', 3), ('873', 3), ('875', 5), ('876', 4), ('88', 22), ('880', 2), ('882', 6), ('883', 2), ('886', 4), ('888', 3), ('89', 22), ('890', 4), ('891', 4), ('89100', 10), ('895', 3), ('896', 3), ('898', 2), ('8a', 4), ('8bit', 9), ('90', 56), ('9000', 7), ('901', 2), ('902', 4), ('903', 2), ('904', 5), ('907', 3), ('908', 3), ('91', 65), ('911', 2), ('914', 2), ('916', 3), ('919', 5), ('92', 54), ('924', 2), ('925', 3), ('926', 4), ('928', 2), ('9293', 5), ('93', 74), ('930', 7), ('932', 4), ('933', 3), ('936', 2), ('94', 19), ('942', 4), ('944', 3), ('947', 5), ('949', 4), ('95', 12), ('95035', 2), ('95051', 6), ('955', 5), ('956', 4), ('957', 5), ('96', 13), ('961', 3), ('9646128', 3), ('969', 3), ('97', 24), ('972', 2), ('974', 3), ('975', 4), ('977', 5), ('979', 4), ('98', 11), ('980', 4), ('982', 6), ('984', 4), ('986', 5), ('988', 5), ('989', 3), ('99', 14), ('990', 4), ('994', 3), ('995', 4), ('996', 6), ('998', 4), ('999', 6), ('a1141', 5), ('a4', 4), ('aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaauuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuugggggggggggggggg', 3), ('aargh', 6), ('ab', 10), ('abandon', 5), ('abc', 65), ('abil', 20), ('abl', 75), ('abofi', 4), ('abort', 1), ('abpsoft', 7), ('absolut', 16), ('abstract', 6), ('absurd', 4), ('ac', 3), ('acadien', 3), ('acceler', 39), ('accept', 28), ('access', 49), ('accid', 2), ('accomod', 3), ('accompani', 4), ('accomplish', 8), ('account', 9), ('accumul', 3), ('accur', 3), ('accus', 3), ('acdalca', 2), ('achiev', 4), ('achkar', 11), ('acker', 9), ('acknowledg', 3), ('acquir', 9), ('acsubuffaloedu', 23), ('act', 12), ('action', 29), ('activ', 22), ('acton', 4), ('actual', 8), ('actuari', 3), ('ad', 37), ('ada', 13), ('adam', 28), ('adapt', 8), ('add', 53), ('addit', 43), ('address', 66), ('adequ', 4), ('adg', 3), ('adirondack', 6), ('adjust', 7), ('admin', 3), ('administr', 13), ('admir', 3), ('admiss', 1), ('admit', 11), ('admittedli', 2), ('adob', 5), ('adobecom', 5), ('adopt', 5), ('adrian', 16), ('advanc', 74), ('advantag', 30), ('advertis', 12), ('advic', 8), ('advis', 2), ('advoc', 2), ('aesthet', 3), ('affect', 5), ('affili', 13), ('afight', 3), ('afraid', 4), ('afternoon', 9), ('ag', 12), ('against', 90), ('agallagh', 2), ('agent', 6), ('aggress', 3), ('ago', 41), ('agre', 45), ('agreement', 9), ('ah', 7), ('ahead', 9), ('ahl', 34), ('ahlnewsrequest', 3), ('ahv', 5), ('ai', 3), ('aik', 5), ('aim', 4), ('ain', 5), ('air', 12), ('aix', 17), ('ajaff', 4), ('aka', 5), ('al', 29), ('ala', 10), ('alabama', 5), ('alan', 16), ('alarm', 2), ('alberta', 9), ('alchemychemutorontoca', 36), ('alex', 13), ('alexand', 9), ('alexei', 5), ('alfalfacom', 3), ('algorithm', 3), ('ali', 12), ('alia', 9), ('alink', 2), ('allan', 14), ('allberi', 4), ('allen', 5), ('allez', 3), ('alloc', 22), ('allow', 73), ('allround', 2), ('allstar', 5), ('alltim', 5), ('almighti', 2), ('alon', 14), ('alot', 13), ('alpo', 5), ('alright', 3), ('alt', 5), ('alter', 2), ('altern', 14), ('altogeth', 8), ('altsourc', 2), ('aluminum', 11), ('am2x', 3), ('amaz', 11), ('america', 7), ('american', 36), ('amiga', 72), ('amount', 16), ('amour', 14), ('analys', 2), ('analysi', 7), ('analyst', 6), ('anderson', 12), ('andersson', 7), ('andi', 21), ('andolina', 4), ('andr', 16), ('andrea', 7), ('andrebeck', 7), ('andrei', 3), ('andrew', 80), ('andrewcmuedu', 54), ('andreychuk', 14), ('andybgsuedu', 6), ('angel', 36), ('angelo', 4), ('anger', 3), ('angl', 6), ('angri', 2), ('anim', 26), ('ann', 6), ('anna', 5), ('annarborappliconslbcom', 7), ('annoi', 15), ('annot', 4), ('announc', 44), ('annual', 14), ('anon', 2), ('anonym', 28), ('ansi', 11), ('answer', 71), ('anthoni', 6), ('anticip', 2), ('antonio', 3), ('anybodi', 53), ('anymor', 5), ('anywai', 31), ('aodcgovau', 4), ('ap', 5), ('apanjabi', 3), ('api', 15), ('apollo', 10), ('apolog', 6), ('app', 39), ('appar', 11), ('appear', 60), ('append', 2), ('appendix', 3), ('appl', 13), ('applaud', 1), ('applecom', 9), ('appli', 22), ('applic', 248), ('applicationshel', 5), ('appoint', 2), ('appreci', 77), ('approach', 13), ('appropri', 16), ('apr', 11), ('apricot', 3), ('april', 51), ('ar', 6), ('arbitrari', 4), ('arbortextcom', 3), ('arc', 3), ('archi', 5), ('architect', 1), ('architectur', 7), ('archiv', 32), ('archivenam', 4), ('arctic', 3), ('area', 54), ('arena', 29), ('arg', 39), ('argc', 17), ('argu', 6), ('argument', 20), ('argv', 27), ('ari', 3), ('arielyorkuca', 2), ('arm', 5), ('arpa', 8), ('arrai', 4), ('arrang', 7), ('arriv', 9), ('arrog', 4), ('arrow', 7), ('arsen', 3), ('art', 5), ('arthur', 3), ('artic', 3), ('articl', 319), ('artifici', 3), ('artist', 6), ('artu', 3), ('asap', 3), ('ascii', 8), ('asent', 7), ('asher', 8), ('ashkar', 7), ('ashton', 9), ('asid', 5), ('ask', 57), ('ass', 20), ('assembl', 5), ('assess', 8), ('asset', 2), ('asshol', 3), ('assign', 7), ('assist', 28), ('associ', 30), ('assum', 35), ('astonish', 3), ('astro', 5), ('astronomi', 8), ('asynchron', 5), ('at', 3), ('athena', 17), ('atla', 3), ('atlanta', 18), ('atmospher', 2), ('atom', 7), ('att15', 3), ('att17', 4), ('att19', 5), ('attach', 6), ('attack', 11), ('attempt', 25), ('attend', 19), ('attende', 3), ('attent', 11), ('attitud', 16), ('attribut', 20), ('aud', 3), ('audett', 3), ('audienc', 10), ('audio', 2), ('austin', 3), ('australia', 9), ('austria', 11), ('author', 53), ('auto', 3), ('autom', 6), ('automat', 26), ('aux', 3), ('av', 10), ('avail', 218), ('avenu', 8), ('averag', 34), ('averwald', 4), ('avoid', 23), ('aw', 5), ('awai', 50), ('awar', 2), ('award', 21), ('awesom', 9), ('ax', 6), ('axelsson', 13), ('ay', 3), ('az', 2), ('babych', 4), ('bachovchin', 3), ('back', 149), ('background', 37), ('backstrom', 5), ('backup', 4), ('bad', 68), ('baddraw', 3), ('bade', 9), ('badli', 2), ('badmatch', 8), ('bai', 34), ('bait', 5), ('baker', 5), ('balanc', 4), ('ball', 5), ('ballentin', 10), ('ballgam', 3), ('baltimor', 5), ('band', 5), ('bandwaggon', 3), ('bandwidth', 11), ('bang', 4), ('banko', 3), ('bar', 20), ('barn', 4), ('baron', 3), ('barr', 6), ('barrasso', 13), ('barri', 3), ('bart', 6), ('base', 78), ('basebal', 71), ('bash', 3), ('basi', 11), ('basic', 21), ('basketbal', 10), ('bassen', 9), ('battl', 3), ('baud', 3), ('baun', 5), ('bb', 5), ('bbncom', 4), ('bboard', 5), ('bc', 11), ('bd', 4), ('bdf', 10), ('beam', 8), ('bear', 9), ('bearcom', 3), ('beat', 62), ('beaten', 3), ('beaupr', 7), ('beauti', 4), ('beck', 21), ('becom', 7), ('bee', 3), ('beer', 11), ('beezer', 4), ('befor', 156), ('beg', 3), ('began', 8), ('begin', 13), ('behalf', 3), ('behavior', 11), ('behaviour', 5), ('behind', 29), ('belfour', 14), ('believ', 63), ('bell', 9), ('bellow', 11), ('belong', 22), ('belov', 3), ('bemybabi', 3), ('bench', 12), ('benefit', 2), ('benjamin', 6), ('benni', 6), ('beranek', 7), ('bergeron', 2), ('bergman', 6), ('berkelei', 5), ('berlin', 5), ('berni', 5), ('berninaethzch', 5), ('bernward', 7), ('berri', 2), ('berth', 3), ('berub', 6), ('best', 138), ('bet', 17), ('beta', 3), ('better', 122), ('bettman', 4), ('beveren', 3), ('beyond', 5), ('bg', 9), ('bias', 8), ('bibliographi', 2), ('big', 57), ('bigbootewpiedu', 3), ('bigger', 7), ('biggest', 35), ('bigwpiwpiedu', 3), ('bill', 40), ('bim', 4), ('bin', 21), ('binari', 47), ('bind', 23), ('binghamton', 6), ('birthdai', 2), ('bit', 63), ('bitblt', 2), ('bite', 3), ('bitmap', 28), ('bitnet', 5), ('bj', 3), ('bjoern', 4), ('bks2', 4), ('black', 38), ('blackhawk', 17), ('blade', 8), ('blame', 11), ('blank', 4), ('blast', 6), ('blink', 18), ('block', 13), ('blood', 9), ('bloodgam', 3), ('bloom', 3), ('blow', 6), ('blown', 4), ('blowout', 8), ('blue', 121), ('blueston', 3), ('blurb', 4), ('bnrca', 5), ('bo', 52), ('board', 43), ('bob', 76), ('bobbi', 19), ('bodi', 18), ('boi', 18), ('bomber', 6), ('bondra', 4), ('bonehead', 5), ('bonn', 4), ('bonu', 3), ('book', 38), ('boomer', 3), ('boora', 4), ('boot', 9), ('border', 9), ('bore', 19), ('bori', 6), ('borqu', 3), ('boss', 3), ('boston', 97), ('bother', 13), ('bottl', 1), ('bottom', 5), ('bought', 9), ('boulder', 7), ('bounc', 9), ('bound', 7), ('bourqu', 16), ('bout', 5), ('boutch', 3), ('bowl', 6), ('bowman', 17), ('box', 54), ('bozrah', 3), ('bp', 6), ('brad', 20), ('bradlei', 13), ('brain', 17), ('branch', 2), ('brand', 5), ('brashear', 4), ('brave', 8), ('break', 41), ('breakawai', 6), ('breaker', 21), ('brendan', 4), ('brent', 10), ('brenz', 3), ('breton', 7), ('brett', 5), ('bri', 3), ('brian', 47), ('brief', 2), ('briefli', 3), ('bright', 3), ('brilliant', 2), ('brind', 13), ('bring', 17), ('bristol', 5), ('britain', 3), ('british', 6), ('britishlemieux', 3), ('brittenson', 4), ('broadcast', 25), ('broadwai', 4), ('broke', 5), ('broken', 8), ('brook', 5), ('broten', 2), ('brother', 1), ('brought', 14), ('brown', 21), ('bruce', 12), ('bruin', 82), ('brunet', 4), ('brutal', 5), ('bryan', 21), ('bryankstrous', 4), ('bs', 3), ('bsc', 3), ('bsd', 7), ('btw', 19), ('bu', 6), ('buchberg', 6), ('buck', 3), ('buckypnlgov', 3), ('buf', 85), ('buff', 4), ('buffalo', 91), ('buffer', 27), ('bug', 25), ('buggi', 2), ('bui', 19), ('build', 85), ('builder', 26), ('built', 27), ('builtin', 17), ('bull', 4), ('bulldog', 3), ('bullet', 3), ('bunch', 16), ('bundl', 4), ('bunni', 7), ('bure', 22), ('burger', 5), ('burgh', 4), ('burk', 4), ('burn', 13), ('burr', 8), ('burt', 6), ('bushbabi', 3), ('busi', 21), ('buster', 3), ('butch', 6), ('butcher', 5), ('butt', 5), ('butter', 3), ('butthead', 3), ('button', 60), ('buttonpressmask', 6), ('buzz', 7), ('bw', 6), ('bwtwo0', 6), ('bwtwo1', 7), ('byte', 24), ('c4zciiftn', 3), ('c5ff', 4), ('ca', 43), ('cabl', 11), ('cach', 4), ('cadkeycom', 7), ('cafal', 3), ('cage', 3), ('caj', 2), ('cal', 64), ('cal2d', 3), ('calcul', 2), ('calder', 9), ('caldwell8102', 4), ('calendar', 2), ('calgari', 64), ('california', 6), ('call', 222), ('callback', 28), ('cam', 4), ('cambridg', 12), ('came', 44), ('camera', 7), ('campbel', 12), ('campi', 3), ('canada', 57), ('canadian', 42), ('canadien', 17), ('cancel', 3), ('candid', 6), ('cannuck', 4), ('cant', 3), ('canuck', 41), ('canva', 14), ('cap', 88), ('capabl', 22), ('cape', 8), ('capit', 39), ('capricorntaiselcomtw', 3), ('capslock', 10), ('captain', 52), ('captur', 7), ('car', 4), ('carbonneau', 6), ('card', 64), ('care', 29), ('career', 10), ('carl', 11), ('carmel', 3), ('carnegi', 9), ('carnei', 6), ('carol', 4), ('carolina', 6), ('carpent', 9), ('carri', 20), ('carson', 18), ('carumba', 3), ('case', 79), ('casei', 5), ('cash', 5), ('cashman', 6), ('casorg', 6), ('cassel', 9), ('cat', 2), ('catch', 16), ('categori', 6), ('caught', 8), ('caus', 43), ('cb', 3), ('cb3', 4), ('cbc', 26), ('cbnewshcbattcom', 3), ('cbnewsicbattcom', 4), ('cbnewskcbattcom', 2), ('cc', 11), ('ccdb', 5), ('ccoption', 2), ('ccuumanitobaca', 17), ('cd', 10), ('cdi', 2), ('cdkaupan', 5), ('cdn', 3), ('cec1wustledu', 17), ('cedex', 4), ('celebr', 2), ('cell', 18), ('center', 35), ('centerlinecom', 6), ('centr', 24), ('central', 7), ('certain', 12), ('certainli', 20), ('cflag', 3), ('cg2', 5), ('cg4', 3), ('cg6', 7), ('cgfour', 5), ('cgfour0', 7), ('cgy', 12), ('ch', 4), ('cha', 2), ('chair', 4), ('chaisson', 3), ('chamber', 7), ('champ', 27), ('champion', 20), ('championship', 17), ('chan', 3), ('chanc', 37), ('chang', 104), ('channel', 6), ('chao', 1), ('chappel', 3), ('chapter', 3), ('char', 68), ('charact', 57), ('charg', 7), ('charl', 16), ('charli', 8), ('chart', 14), ('chase', 6), ('cheap', 20), ('cheaper', 3), ('cheapshot', 4), ('check', 90), ('checker', 6), ('cheer', 13), ('cheever', 3), ('chelio', 27), ('cherri', 37), ('chest', 5), ('chevelda', 11), ('chew', 3), ('chhabra', 12), ('chi', 49), ('chiasson', 9), ('chicago', 67), ('chief', 2), ('child', 9), ('chines', 8), ('ching', 5), ('chip', 9), ('chmod', 2), ('chocol', 3), ('choic', 30), ('choke', 5), ('choos', 12), ('chop', 1), ('chopinudeledu', 8), ('chose', 5), ('chosen', 12), ('chown', 5), ('chri', 18), ('christ', 5), ('christian', 11), ('christoph', 6), ('chubbi', 3), ('chuck', 7), ('chump', 3), ('chunk', 5), ('chuq', 14), ('church', 3), ('ciccarelli', 15), ('circl', 13), ('circumst', 5), ('cire', 3), ('cisohiostateedu', 3), ('citi', 50), ('civic', 4), ('claim', 21), ('clamen', 3), ('clara', 8), ('clark', 21), ('clarkson', 9), ('class', 55), ('classi', 6), ('classic', 10), ('claud', 5), ('clean', 7), ('cleanup', 4), ('clear', 24), ('clearli', 14), ('clement', 7), ('cleveland', 5), ('clevelandfreenetedu', 4), ('click', 11), ('client', 139), ('cliff', 4), ('clinch', 6), ('clint', 7), ('clinton', 9), ('clip', 16), ('clock', 5), ('clone', 8), ('close', 43), ('closer', 3), ('closest', 3), ('closet', 5), ('closeup', 3), ('cloud', 2), ('club', 19), ('clue', 5), ('cluster', 5), ('clutch', 4), ('cmdr', 3), ('cmdtool', 5), ('cmsccwayneedu', 3), ('cmuedu', 2), ('coach', 111), ('coast', 3), ('cobra', 18), ('cockroft', 4), ('code', 117), ('coffei', 19), ('cogsciedacuk', 3), ('coin', 9), ('coincid', 5), ('col', 17), ('cold', 2), ('colin', 5), ('coliseum', 3), ('coll', 5), ('collaps', 2), ('colleagu', 3), ('collect', 11), ('collector', 4), ('colleg', 16), ('collingridg', 7), ('colon', 7), ('color', 171), ('colorado', 8), ('colorcel', 4), ('colormap', 87), ('colour', 15), ('columbiaedu', 6), ('column', 9), ('com', 2), ('combin', 14), ('come', 58), ('comeback', 5), ('comm', 2), ('command', 56), ('commandlin', 7), ('comment', 47), ('commerci', 37), ('commit', 7), ('common', 19), ('commonli', 3), ('commun', 30), ('compani', 25), ('compar', 24), ('comparison', 7), ('compat', 35), ('compens', 3), ('compet', 6), ('competit', 10), ('compil', 72), ('complain', 19), ('complaint', 5), ('complancsacuk', 5), ('complangpostscript', 3), ('complet', 54), ('complex', 6), ('compliant', 8), ('complic', 8), ('compon', 6), ('compos', 12), ('composit', 1), ('compress', 14), ('compsourcesx', 15), ('compuserv', 2), ('comput', 118), ('compwindowsx', 19), ('compwindowsxannounc', 3), ('conach', 3), ('concept', 3), ('concern', 12), ('conclus', 8), ('concurr', 7), ('condit', 5), ('conf', 3), ('confer', 73), ('confid', 4), ('config', 2), ('configur', 41), ('confirm', 8), ('conflict', 8), ('conform', 4), ('confus', 11), ('congeni', 4), ('congrat', 2), ('congruent', 6), ('connect', 56), ('consecut', 7), ('consid', 47), ('consider', 11), ('consist', 16), ('consol', 14), ('consortium', 40), ('constantli', 3), ('construct', 10), ('consult', 12), ('contact', 94), ('contain', 39), ('contend', 11), ('content', 21), ('contest', 41), ('context', 17), ('continu', 30), ('contract', 20), ('contractu', 12), ('contrari', 2), ('contrib', 95), ('contribut', 25), ('contributor', 6), ('control', 49), ('conveni', 7), ('convent', 10), ('convers', 17), ('convert', 45), ('convex', 4), ('convinc', 5), ('coohil', 4), ('cook', 5), ('cooki', 1), ('cool', 7), ('coordin', 9), ('copi', 61), ('copp', 2), ('copyleft', 2), ('copyright', 15), ('cordial', 19), ('core', 10), ('cormack', 3), ('cornel', 5), ('corner', 26), ('corp', 10), ('corpor', 36), ('correct', 33), ('correctli', 11), ('correspond', 8), ('corson', 3), ('cose', 2), ('cost', 17), ('cote', 2), ('cougarmania', 3), ('coulman', 11), ('count', 34), ('counterpart', 3), ('counti', 3), ('countri', 12), ('coupl', 40), ('cours', 90), ('courtesi', 17), ('courtnal', 26), ('cover', 22), ('coverag', 66), ('cow', 7), ('coward', 6), ('cp', 1), ('cpu', 41), ('cr', 4), ('craftcampclarksonedu', 4), ('craig', 9), ('crap', 9), ('crash', 12), ('craven', 9), ('craycom', 13), ('crazi', 6), ('creas', 11), ('creat', 108), ('creation', 9), ('credibl', 3), ('credit', 13), ('creep', 3), ('creighton', 4), ('crew', 4), ('crime', 5), ('critic', 8), ('cross', 20), ('crosscheck', 6), ('crowd', 14), ('crucial', 4), ('crush', 4), ('crusher', 3), ('cs', 7), ('cs902043', 2), ('csabuedu', 2), ('cscmuedu', 13), ('cscoloradoedu', 4), ('csdnewshoststanfordedu', 5), ('csh', 4), ('csissun11eevirginiaedu', 3), ('csnorg', 4), ('csnpsnavymil', 4), ('cspurdueedu', 4), ('csrochesteredu', 7), ('cstuberlind', 5), ('csualbertaca', 11), ('cswiscedu', 3), ('ct', 4), ('ctrcolumbiaedu', 4), ('ctrl', 18), ('ctwm', 3), ('ctypeh', 2), ('cu', 4), ('cub', 5), ('cullen', 8), ('cunew', 3), ('cunixbcccolumbiaedu', 12), ('cunixcbitnet', 6), ('cunneyworth', 3), ('cup', 111), ('curb', 3), ('curiou', 7), ('current', 99), ('curs', 6), ('cursor', 60), ('cursoro', 3), ('curt', 7), ('curti', 9), ('custom', 15), ('customiz', 4), ('cut', 44), ('cycl', 2), ('cyt', 5), ('czech', 8), ('d3e758', 3), ('da', 5), ('dahlen', 9), ('dahlquist', 8), ('dai', 69), ('daigl', 11), ('dal', 2), ('dale', 17), ('dalla', 11), ('damag', 3), ('dammit', 3), ('damn', 11), ('damphouss', 8), ('dan', 27), ('danger', 6), ('daniel', 29), ('danni', 4), ('danno', 3), ('dare', 19), ('dark', 4), ('darman', 3), ('darren', 5), ('darryl', 4), ('dars', 4), ('dart', 6), ('dartmouth', 4), ('darwin', 2), ('daryl', 13), ('dastardli', 3), ('data', 71), ('databas', 10), ('date', 24), ('dave', 48), ('davi', 15), ('david', 102), ('davidcraft', 3), ('davidson', 6), ('daytodai', 4), ('dayton', 3), ('db', 4), ('db74', 4), ('dbl', 6), ('dc', 3), ('dchhabra', 17), ('dcr', 9), ('dd', 2), ('de', 15), ('dead', 10), ('deadlin', 5), ('deal', 61), ('dean', 11), ('dear', 6), ('death', 14), ('debat', 4), ('debug', 4), ('dec', 48), ('decad', 10), ('decemb', 3), ('decent', 14), ('decid', 42), ('decis', 13), ('declar', 4), ('decnet', 21), ('decod', 3), ('decreas', 3), ('decruyenaer', 3), ('decstat', 11), ('decwindow', 22), ('dedic', 5), ('deep', 5), ('deepak', 21), ('deeper', 3), ('default', 61), ('defaultrootwindow', 7), ('defaultscreen', 3), ('defeat', 5), ('defenceman', 5), ('defend', 12), ('defens', 63), ('defenseman', 11), ('defensemen', 6), ('defin', 64), ('definit', 37), ('deg', 7), ('degre', 5), ('delai', 16), ('delarocq', 7), ('delawar', 3), ('delet', 29), ('dell', 4), ('delphibeckmanuiucedu', 2), ('demand', 9), ('demer', 9), ('demo', 26), ('demon', 3), ('demonstr', 16), ('deni', 20), ('denni', 7), ('denot', 4), ('depart', 24), ('depend', 23), ('depriv', 3), ('dept', 21), ('depth', 30), ('der', 15), ('derek', 18), ('deriv', 4), ('derrel', 3), ('derrick', 6), ('derril', 3), ('descartesuwaterlooca', 3), ('describ', 19), ('descript', 29), ('descriptor', 9), ('deserv', 22), ('design', 31), ('desir', 6), ('desktop', 20), ('desper', 7), ('despit', 16), ('desqview', 19), ('destin', 3), ('destini', 4), ('destroi', 13), ('det', 62), ('detail', 21), ('detect', 11), ('determin', 30), ('detroit', 84), ('detroittoronto', 5), ('dev', 25), ('develop', 64), ('devguid', 9), ('devic', 21), ('devil', 97), ('devineni', 3), ('devot', 4), ('dg', 9), ('dhaywood', 6), ('di', 12), ('dialog', 21), ('dick', 12), ('dictat', 5), ('dictionari', 2), ('die', 14), ('diet', 3), ('diff', 4), ('differ', 101), ('difficult', 11), ('difficulti', 4), ('digest', 2), ('digit', 27), ('dinamo', 3), ('dineen', 24), ('dino', 10), ('dir', 4), ('direct', 29), ('directcolor', 4), ('directli', 21), ('director', 3), ('directori', 38), ('dirk', 4), ('dirt', 3), ('dirtbag', 3), ('dirti', 14), ('disabl', 2), ('disadvantag', 4), ('disagre', 9), ('disappear', 5), ('disappoint', 18), ('disclaim', 13), ('discov', 5), ('discret', 2), ('discuss', 25), ('dish', 8), ('disk', 48), ('dislik', 5), ('dispatch', 3), ('displai', 266), ('dist', 3), ('distanc', 2), ('distinguish', 2), ('distribut', 71), ('distributor', 3), ('district', 3), ('disturb', 2), ('div', 8), ('dive', 8), ('diverg', 2), ('divid', 4), ('divis', 98), ('djurgarden', 3), ('dla', 6), ('dm', 8), ('do', 578), ('doc', 12), ('document', 43), ('doesnt', 3), ('dog', 14), ('dollar', 3), ('domain', 18), ('domi', 21), ('domin', 15), ('donat', 9), ('done', 66), ('donnelli', 9), ('dont', 7), ('donut', 2), ('door', 4), ('dope', 4), ('dot', 4), ('doubl', 9), ('doublehead', 3), ('doubt', 16), ('doubter', 4), ('doug', 46), ('dougla', 9), ('douri', 6), ('dozen', 12), ('dpi', 2), ('dpscouk', 9), ('dpy', 19), ('dr', 23), ('draft', 59), ('drag', 7), ('dragon', 3), ('drake', 13), ('draw', 107), ('drawabl', 6), ('drawindex', 7), ('drawingarea1', 2), ('drawn', 11), ('drd', 4), ('dream', 7), ('dreamer', 3), ('dree', 3), ('dress', 4), ('dresser', 3), ('drew', 3), ('drill', 2), ('driscol', 9), ('drive', 25), ('drivel', 2), ('driven', 3), ('driver', 31), ('droopi', 4), ('drop', 20), ('drove', 3), ('druce', 2), ('dryden', 3), ('dsc', 4), ('dsdescom', 9), ('dsweenei', 2), ('dsysv', 6), ('du', 8), ('dubiou', 4), ('dude', 5), ('dudepcscom', 4), ('due', 35), ('duffand', 5), ('dumb', 6), ('dump', 17), ('dunno', 6), ('durham', 3), ('dusseldorf', 8), ('duti', 2), ('dvb', 8), ('dy', 4), ('dynam', 9), ('dynasti', 11), ('dyoung', 5), ('ea', 6), ('ear', 3), ('earhart', 4), ('earl', 9), ('earlier', 16), ('earlyseason', 4), ('eas', 4), ('easi', 38), ('easier', 15), ('easili', 20), ('east', 18), ('eastern', 3), ('eat', 4), ('ec', 3), ('ecac', 7), ('echo', 71), ('ed', 23), ('edelweiss', 3), ('edg', 11), ('edinburgh', 5), ('edit', 21), ('editor', 46), ('edm', 19), ('edmonton', 37), ('educ', 16), ('edward', 5), ('effect', 35), ('effici', 5), ('effort', 26), ('ego', 5), ('eight', 2), ('einstein', 4), ('eisler', 5), ('eklund', 6), ('elbel', 3), ('elbow', 4), ('electr', 7), ('electron', 13), ('elegantli', 1), ('element', 4), ('elimin', 6), ('elincoat', 5), ('elinenergieanwendung', 5), ('eliteserien', 3), ('elitserien', 3), ('ellett', 2), ('elli', 10), ('ellwel', 2), ('elynuik', 2), ('em', 6), ('emac', 26), ('email', 192), ('emb', 2), ('embed', 8), ('emeri', 3), ('emerson', 5), ('emot', 9), ('emploi', 3), ('employ', 7), ('empti', 1), ('emrick', 1), ('emu', 2), ('emul', 38), ('en', 10), ('enabl', 16), ('encapsul', 7), ('enclosur', 4), ('encod', 5), ('encount', 6), ('encourag', 3), ('end', 18), ('endif', 23), ('endors', 2), ('energi', 2), ('enforc', 7), ('engin', 40), ('england', 12), ('english', 17), ('engsuncom', 4), ('enhanc', 19), ('enjoi', 14), ('ensur', 7), ('enter', 26), ('entertain', 3), ('enterwindowmask', 3), ('enthusiasm', 2), ('entir', 24), ('entri', 101), ('env', 2), ('environ', 52), ('eof', 16), ('eosericssons', 3), ('eosncsuedu', 19), ('ep', 6), ('episod', 9), ('epoch', 7), ('equal', 8), ('equip', 13), ('equival', 6), ('er', 3), ('era', 8), ('eras', 9), ('eric', 18), ('ericsson', 3), ('erik', 1), ('errei', 9), ('error', 122), ('esc', 5), ('escal', 4), ('escap', 23), ('esd', 2), ('especi', 31), ('espn', 167), ('espn2', 15), ('essa', 5), ('essensa', 10), ('essenti', 5), ('est', 2), ('establish', 5), ('et', 9), ('ethernet', 49), ('ethic', 3), ('etxmesa', 3), ('etxonss', 9), ('eulerlbsmsuedu', 5), ('euro', 7), ('euroblood', 3), ('europ', 23), ('european', 47), ('ev', 3), ('evalu', 11), ('evan', 6), ('even', 9), ('event', 146), ('eventhandl', 3), ('eventloop', 2), ('eventu', 8), ('everybodi', 10), ('everyon', 37), ('everyth', 29), ('evid', 9), ('exact', 14), ('exactli', 37), ('examin', 3), ('exampl', 78), ('exassat', 3), ('exce', 2), ('excel', 19), ('except', 14), ('excerpt', 5), ('exchang', 2), ('excit', 13), ('exclud', 4), ('exclus', 2), ('excus', 13), ('exec', 9), ('execut', 26), ('exercis', 3), ('exhibit', 12), ('exil', 3), ('exist', 49), ('exit', 32), ('exp', 3), ('expand', 6), ('expans', 12), ('expect', 58), ('expens', 4), ('experi', 28), ('experienc', 9), ('expert', 6), ('expir', 3), ('explain', 11), ('explan', 5), ('explicit', 4), ('explicitli', 5), ('explor', 4), ('expolcsmitedu', 13), ('export', 51), ('exportlcsmitedu', 43), ('expos', 32), ('exposur', 5), ('exposuremask', 3), ('express', 10), ('ext', 10), ('extend', 18), ('extens', 55), ('extern', 3), ('extra', 13), ('extract', 12), ('extrem', 7), ('ey', 9), ('eyesor', 3), ('f1hh', 3), ('f3', 3), ('face', 21), ('faceoff', 13), ('facil', 8), ('facilit', 2), ('fact', 47), ('factor', 10), ('fail', 39), ('fair', 7), ('fairli', 11), ('faith', 9), ('fall', 21), ('fals', 27), ('fame', 6), ('famili', 6), ('familiar', 9), ('fan', 167), ('fancypseudograph', 3), ('faq', 46), ('faqcraft', 3), ('far', 64), ('farenebt', 6), ('farenel', 3), ('farm', 8), ('fashion', 3), ('fast', 20), ('faster', 17), ('fastest', 3), ('fat', 2), ('fatal', 12), ('father', 3), ('fault', 16), ('favor', 3), ('favorit', 13), ('favour', 4), ('fax', 107), ('fb', 4), ('fck', 3), ('fd', 4), ('fear', 3), ('featur', 73), ('feb', 2), ('fedorov', 8), ('fedyk', 1), ('fee', 14), ('feed', 18), ('feedback', 7), ('feel', 59), ('feet', 3), ('felix', 10), ('fell', 6), ('felsner', 5), ('felt', 5), ('ferguson', 15), ('ferment', 4), ('ferraro', 6), ('fewer', 1), ('fg', 6), ('fi', 8), ('fidonet', 5), ('field', 9), ('fife', 3), ('fifth', 4), ('fight', 31), ('figur', 30), ('file', 370), ('filemgr', 2), ('filenam', 35), ('fileselector', 5), ('fill', 13), ('filter', 8), ('fin', 6), ('finaboabofi', 6), ('final', 96), ('financi', 5), ('find', 109), ('fine', 40), ('finger', 11), ('finish', 18), ('finland', 23), ('finn', 4), ('finnish', 20), ('fire', 17), ('firebird', 3), ('first', 251), ('fish', 13), ('fisher', 3), ('fit', 5), ('five', 18), ('fix', 56), ('fking', 3), ('fl', 5), ('flag', 30), ('flagship', 2), ('flame', 107), ('flash', 7), ('flat', 4), ('flatteri', 6), ('flaunt', 2), ('flavor', 3), ('fleishman', 3), ('fleur', 3), ('fleuri', 24), ('flexibl', 7), ('flick', 2), ('flip', 2), ('florida', 10), ('flow', 6), ('flower', 4), ('fluid', 4), ('fly', 8), ('flyer', 30), ('fm', 3), ('fmsalvat', 6), ('fn', 1), ('focu', 23), ('fold', 3), ('foligno', 8), ('folk', 23), ('folli', 3), ('follow', 133), ('followup', 4), ('font', 151), ('fool', 8), ('foot', 3), ('footbal', 10), ('forb', 4), ('forc', 29), ('foreground', 14), ('foreign', 3), ('forev', 4), ('forget', 13), ('forgot', 5), ('fork', 9), ('form', 37), ('format', 50), ('former', 8), ('formerli', 12), ('forsberg', 2), ('fortecstuftsedu', 3), ('forth', 4), ('fortun', 7), ('forum', 2), ('forward', 40), ('foul', 13), ('foundat', 10), ('four', 33), ('fourth', 4), ('fp', 4), ('fpccstructreturn', 7), ('fprintf', 50), ('fr', 6), ('frack', 3), ('fractal', 2), ('frame', 26), ('framebuff', 12), ('framemak', 3), ('franc', 14), ('franchis', 9), ('franci', 43), ('francisco', 10), ('frank', 24), ('frankli', 5), ('franti', 3), ('frasersfuca', 6), ('freak', 3), ('fred', 5), ('freddyersysedmontonabca', 5), ('fredericton', 4), ('free', 87), ('freeli', 5), ('freenetcarletonca', 6), ('freenetvictoriabcca', 4), ('freewar', 6), ('french', 8), ('frequent', 11), ('fresh', 3), ('fridai', 12), ('friedman', 6), ('friend', 15), ('front', 27), ('frontend', 4), ('frustrat', 5), ('ft', 5), ('ftmsbrownastroatcuucp', 3), ('ftmsuucp', 6), ('ftp', 130), ('ftpabl', 2), ('ftpuunet', 4), ('fuck', 10), ('fuentezcom', 2), ('fuer', 3), ('fuhr', 54), ('full', 48), ('fulli', 5), ('fulton', 4), ('fun', 9), ('function', 146), ('funni', 3), ('furi', 4), ('furlei', 3), ('furthermor', 2), ('futil', 2), ('futur', 26), ('fuzzfac', 3), ('fwiuvanl', 2), ('ga', 7), ('gaa', 3), ('gadget', 3), ('gainei', 49), ('galaxi', 5), ('gallagh', 2), ('gallant', 6), ('gallei', 13), ('gallichio', 6), ('galvin', 7), ('galvint', 7), ('game', 680), ('gaoler', 3), ('garbag', 5), ('garcia', 3), ('gari', 53), ('garpenlov', 7), ('garri', 1), ('garryola', 3), ('garth', 2), ('gartner', 9), ('gasch', 4), ('gatewai', 7), ('gaudreau', 11), ('gaussmedharvardedu', 11), ('gave', 21), ('gb', 6), ('gballent', 13), ('gc', 19), ('gcc', 31), ('ge', 4), ('gee', 5), ('gener', 83), ('geni', 5), ('geoff', 11), ('geometri', 6), ('geophys', 4), ('geordi', 3), ('georg', 34), ('georgeh', 4), ('gerald', 59), ('gerard', 19), ('gerardodriscol', 4), ('german', 40), ('germanborn', 8), ('germani', 19), ('gerri', 4), ('gesmbh', 5), ('get', 545), ('getapplicationshellwidgetclass', 1), ('getter', 3), ('getwmshellwidgetclass', 1), ('gfxbase', 4), ('ghostscript', 4), ('ghostview', 2), ('giant', 7), ('giantsrequest', 2), ('gibson', 14), ('gif', 21), ('gil', 5), ('gilhen', 4), ('gill', 10), ('gilmour', 48), ('gimm', 4), ('give', 121), ('given', 62), ('gjhsun', 4), ('gk', 3), ('gl', 54), ('glacial', 3), ('glad', 11), ('gld', 30), ('glen', 3), ('glenn', 13), ('global', 4), ('glove', 4), ('glxdraw', 4), ('glxgetconfig', 4), ('glxlink', 4), ('glxmdraw', 6), ('glxunlink', 4), ('glxwinset', 4), ('gm', 34), ('gmt', 6), ('gnu', 14), ('go', 378), ('goal', 180), ('goalding', 3), ('goali', 58), ('goaltend', 19), ('god', 14), ('goddess', 3), ('godfath', 7), ('goe', 35), ('golchowi', 29), ('gold', 8), ('golden', 4), ('golf', 18), ('gone', 17), ('gonna', 5), ('gooch', 7), ('good', 190), ('gordi', 4), ('gordon', 10), ('gore', 6), ('got', 124), ('gothenburg', 3), ('gotta', 8), ('gotten', 11), ('goulet', 4), ('govern', 9), ('gowen', 9), ('gp', 11), ('gr', 13), ('grab', 24), ('graca', 7), ('graduat', 1), ('graham', 11), ('granato', 10), ('grand', 2), ('grandmoth', 3), ('grant', 36), ('grape', 10), ('graph', 35), ('graphic', 128), ('graphig', 3), ('grave', 7), ('grayscal', 5), ('great', 111), ('greater', 12), ('greatest', 3), ('greatli', 24), ('green', 23), ('greet', 5), ('greg', 46), ('gregmeist', 6), ('gregori', 4), ('grei', 6), ('gretzki', 50), ('gripcisupennedu', 3), ('gripe', 7), ('groger', 3), ('ground', 4), ('group', 86), ('grow', 7), ('gtd597a', 15), ('guarante', 11), ('guess', 48), ('gui', 144), ('guid', 19), ('guidelin', 9), ('guru', 8), ('guvaxaccgeorgetownedu', 5), ('gwm', 3), ('gx', 4), ('gxcopi', 5), ('gxxor', 11), ('ha', 3), ('hab', 33), ('hack', 4), ('hacker', 6), ('hadn', 8), ('half', 16), ('halfhour', 3), ('halifax', 5), ('hall', 13), ('hallg', 4), ('hamilton', 16), ('hammer', 1), ('hammerl', 38), ('hamrlik', 5), ('hamster', 3), ('hand', 41), ('handi', 3), ('handl', 40), ('handler', 36), ('hang', 17), ('hannu', 2), ('hansen', 3), ('happen', 72), ('happi', 16), ('har', 13), ('haral', 3), ('hard', 53), ('harder', 2), ('hardi', 5), ('hardli', 10), ('hardwar', 30), ('harila', 2), ('harri', 7), ('hart', 19), ('hartford', 19), ('harvard', 4), ('hasek', 3), ('hat', 9), ('hatcher', 6), ('hate', 22), ('have', 65), ('hawerchuk', 15), ('hawgood', 10), ('hawk', 45), ('hayward', 5), ('hd', 5), ('head', 56), ('header', 23), ('headlin', 3), ('heali', 5), ('healthi', 6), ('healthyuwaterlooca', 5), ('hear', 23), ('heard', 25), ('heart', 8), ('heat', 4), ('heavi', 3), ('heavili', 2), ('hebert', 4), ('heck', 5), ('hedican', 8), ('hei', 23), ('height', 25), ('held', 14), ('heliosathepagov', 8), ('hell', 35), ('hello', 16), ('help', 189), ('helsinki', 10), ('henri', 15), ('herd', 3), ('heritag', 3), ('het', 3), ('hex', 4), ('hextal', 14), ('hi', 68), ('hide', 4), ('hierarchi', 9), ('high', 47), ('highend', 3), ('higher', 56), ('highest', 9), ('highli', 4), ('highlight', 9), ('highstick', 3), ('hill', 4), ('hillsid', 3), ('himself', 12), ('hint', 24), ('hire', 9), ('histori', 15), ('historyth', 3), ('hit', 37), ('hmmmsound', 3), ('hobb', 3), ('hoboken', 3), ('hochreit', 11), ('hockei', 311), ('hockey', 3), ('hold', 31), ('holder', 2), ('hole', 8), ('holi', 2), ('home', 57), ('homeboi', 3), ('honor', 4), ('honour', 19), ('hook', 6), ('hope', 62), ('hopefulli', 10), ('hornet', 6), ('horribl', 4), ('horvath', 3), ('hospit', 5), ('host', 51), ('hostnam', 21), ('hot', 14), ('hoth', 3), ('houdini', 3), ('hour', 9), ('hous', 6), ('houslei', 10), ('houston', 5), ('how', 12), ('howard', 2), ('hp', 61), ('hp9000', 4), ('hpux', 8), ('hrivnak', 15), ('hrudei', 12), ('hs', 3), ('hsdndevharvardedu', 4), ('ht', 5), ('hubert', 3), ('hudsonuvicca', 10), ('huge', 12), ('hugh', 8), ('hull', 13), ('human', 7), ('humour', 3), ('hundr', 4), ('hung', 6), ('hungri', 1), ('hunter', 28), ('huot', 25), ('hurrican', 6), ('hurt', 17), ('hwy', 3), ('hydragatechedu', 3), ('hype', 9), ('ian', 10), ('ibm', 31), ('ic', 101), ('icccm', 9), ('icebreak', 3), ('ick', 4), ('icon', 41), ('icop', 2), ('icscom', 6), ('id', 43), ('idacom', 6), ('idacomhpcom', 12), ('idea', 51), ('ideal', 2), ('ident', 11), ('idiot', 4), ('idl', 4), ('idraw', 3), ('ifdef', 5), ('igdfhgd', 4), ('ignor', 19), ('igor', 3), ('ihl', 13), ('ii', 19), ('iii', 6), ('iiikevin', 3), ('ikea', 3), ('il', 4), ('illeg', 5), ('illinoi', 3), ('illustr', 5), ('im', 6), ('imag', 59), ('imagemagick', 2), ('imagin', 8), ('imak', 10), ('imakefil', 6), ('imho', 16), ('imit', 3), ('immedi', 13), ('imo', 13), ('impact', 3), ('impal', 4), ('implement', 79), ('implementor', 3), ('impli', 10), ('implic', 3), ('import', 19), ('imposs', 2), ('impress', 31), ('improv', 34), ('inch', 3), ('incid', 5), ('includ', 326), ('inclus', 4), ('incom', 7), ('incompat', 4), ('incomplet', 4), ('inconsist', 4), ('incorpor', 7), ('incorrect', 5), ('increas', 12), ('incred', 2), ('indent', 4), ('independ', 8), ('index', 23), ('indian', 5), ('indianapoli', 3), ('indic', 21), ('indigo', 2), ('individu', 33), ('industri', 12), ('inefficientor', 3), ('inet', 4), ('inevit', 1), ('inexperienc', 2), ('inf', 6), ('inferior', 3), ('infin', 3), ('info', 107), ('infodevcamacuk', 4), ('inform', 179), ('informatiktumuenchend', 9), ('ing', 6), ('inherit', 5), ('init', 2), ('initi', 25), ('injur', 12), ('injuri', 25), ('inmat', 3), ('input', 76), ('inputoutput', 2), ('insert', 8), ('insid', 14), ('insight', 5), ('insist', 3), ('insitut', 2), ('inspir', 3), ('instal', 54), ('instanc', 6), ('instant', 2), ('institut', 21), ('instruct', 7), ('insuffici', 1), ('insult', 4), ('int', 63), ('integr', 33), ('intel', 6), ('intellig', 13), ('intend', 10), ('intens', 6), ('intent', 11), ('interact', 26), ('interest', 82), ('interfac', 79), ('intermiss', 7), ('intern', 37), ('internation', 4), ('internet', 66), ('interpret', 17), ('interrupt', 6), ('interview', 26), ('interviewsstanfordedu', 3), ('intrins', 16), ('introduc', 6), ('invalid', 6), ('invers', 4), ('investig', 2), ('invis', 5), ('invok', 15), ('involv', 16), ('ioctl', 3), ('iowa', 5), ('ip', 74), ('ipc', 8), ('ipx', 14), ('irb', 6), ('iri', 5), ('irix', 3), ('iron', 2), ('irsinftudresdend', 7), ('irzr17inftudresdend', 7), ('isl', 50), ('island', 79), ('issu', 24), ('ist', 4), ('istsistsca', 3), ('itali', 7), ('italian', 3), ('item', 23), ('ito2', 3), ('ivi', 13), ('ix', 5), ('ixi', 6), ('j3david', 7), ('jack', 9), ('jackpetrilli', 2), ('jacqu', 4), ('jadetuftsedu', 6), ('jaff', 4), ('jagr', 35), ('jai', 11), ('jake', 8), ('jam', 3), ('jame', 16), ('jan', 16), ('janet', 4), ('jannei', 10), ('januari', 7), ('japanes', 8), ('jarosz', 2), ('jarvi', 10), ('jason', 10), ('jayson', 3), ('jb', 3), ('jbrown', 3), ('jc', 5), ('jca2', 17), ('jd', 7), ('je', 12), ('jeff', 20), ('jerri', 4), ('jersei', 24), ('jess', 8), ('jessea', 7), ('jesu', 8), ('jet', 79), ('jetsessensa', 3), ('jhunixhcfjhuedu', 4), ('jim', 31), ('jimpark', 3), ('jjm', 5), ('jo', 6), ('job', 37), ('joe', 31), ('joe13', 7), ('joel', 15), ('johansson', 7), ('john', 110), ('johnson', 8), ('join', 10), ('joke', 9), ('joker', 3), ('jokerit', 16), ('joliet', 3), ('jon', 12), ('jonathan', 5), ('jone', 14), ('jordan', 5), ('jose', 54), ('joseph', 40), ('jouko', 3), ('journal', 7), ('jr', 6), ('judg', 10), ('juergen', 4), ('juggl', 1), ('jugular', 3), ('juha', 4), ('juli', 3), ('julia', 1), ('julian', 7), ('jump', 3), ('june', 23), ('juneau', 6), ('junior', 7), ('jupitersuncsdunbca', 4), ('just', 325), ('justif', 2), ('justifi', 4), ('jutila', 3), ('kamuck', 3), ('kanada', 3), ('kari', 2), ('kariya', 12), ('karma', 3), ('kaufbeuren', 3), ('kaupang', 5), ('kbw', 9), ('kdka', 3), ('keenan', 27), ('keep', 50), ('kei', 152), ('keikaku', 3), ('keith', 43), ('keller', 31), ('kelli', 12), ('kemppainen', 3), ('ken', 28), ('kennedi', 5), ('kenneth', 3), ('kenni', 3), ('keon', 4), ('kept', 8), ('kerbero', 3), ('kernel', 9), ('kerr', 5), ('kerri', 3), ('ketter', 5), ('kev', 3), ('kevin', 33), ('keybo', 3), ('keyboard', 77), ('keycod', 33), ('keymap', 27), ('keyn', 3), ('keypress', 8), ('keypressmask', 4), ('keysym', 9), ('keyword', 3), ('khmylev', 9), ('kick', 17), ('kid', 12), ('kielbasa', 2), ('kill', 23), ('killer', 7), ('kind', 45), ('kinda', 4), ('king', 95), ('kingdom', 2), ('kingston', 6), ('kinki', 3), ('kipl', 4), ('kirk', 6), ('kirzyc', 2), ('kisio', 10), ('kisseberth', 2), ('kit', 11), ('kitssfuca', 4), ('kiwi', 3), ('kkeller', 28), ('kl', 3), ('klee', 9), ('knee', 7), ('knew', 13), ('knife', 3), ('knight', 2), ('knock', 6), ('know', 302), ('knowledg', 14), ('known', 30), ('kodiak', 3), ('kokudo', 3), ('konstantinov', 2), ('kortelainen', 5), ('kortelaisen', 3), ('kovalenko', 3), ('kovalev', 18), ('kovat', 3), ('koz', 3), ('kozloc', 7), ('kozlov', 7), ('kpccom', 2), ('kubota', 3), ('kuehn', 3), ('kurri', 16), ('kuta', 3), ('kylmaoja', 4), ('l8', 2), ('la', 78), ('lab', 26), ('label', 10), ('laboratori', 18), ('lack', 19), ('lacker', 3), ('ladi', 5), ('lafleur', 4), ('lafontain', 30), ('lai', 2), ('lak', 11), ('lake', 7), ('lamarcolostateedu', 5), ('lamp', 3), ('lan', 15), ('lana', 3), ('land', 2), ('landau', 6), ('lane', 4), ('lang', 5), ('languag', 26), ('lanzo', 8), ('lapoint', 7), ('lar', 2), ('larg', 33), ('larger', 15), ('larmer', 3), ('larocqu', 3), ('larri', 31), ('larrymcrcimmcgilledu', 10), ('laser', 3), ('lastmodifi', 4), ('lat', 10), ('latest', 44), ('latex', 3), ('latter', 10), ('lau', 3), ('laubster', 3), ('laugh', 12), ('laukkanen', 2), ('launch', 4), ('laurel', 2), ('lauri', 5), ('lawrenc', 6), ('layer', 5), ('layout', 7), ('lazaru', 11), ('lazi', 2), ('lb', 4), ('ld', 8), ('ldrunpath', 6), ('le', 22), ('lead', 73), ('leader', 19), ('leadership', 6), ('leaf', 129), ('leafspotvin', 3), ('leagu', 98), ('leaguen', 3), ('learn', 25), ('leas', 3), ('least', 56), ('leav', 35), ('leavewindowmask', 2), ('lebeau', 3), ('leblanc', 3), ('lectur', 3), ('lee', 31), ('lefebvr', 4), ('left', 41), ('legion', 6), ('lehigh', 3), ('lemer', 4), ('lemieux', 69), ('lenarduzzi', 2), ('length', 11), ('leo', 5), ('lesson', 4), ('let', 24), ('letter', 14), ('letterman', 3), ('leung', 3), ('leunggm', 3), ('level', 29), ('lewi', 10), ('li', 6), ('liam', 7), ('lib', 83), ('librari', 84), ('libxextso', 3), ('libxmu', 4), ('licens', 10), ('lidstrom', 5), ('life', 19), ('lift', 7), ('light', 4), ('lighter', 3), ('like', 11), ('liken', 3), ('limit', 46), ('linden', 15), ('lindro', 34), ('lindroo', 6), ('line', 196), ('linesman', 4), ('lineup', 10), ('link', 19), ('linsemen', 3), ('linux', 20), ('lion', 4), ('lionbearcom', 2), ('lipp', 3), ('lisp', 8), ('list', 160), ('listen', 7), ('listserv', 4), ('liter', 1), ('littl', 89), ('littlest', 3), ('litton', 3), ('liu', 4), ('live', 31), ('lm', 2), ('lmarsha', 3), ('ln', 4), ('lnsl', 2), ('lo', 34), ('load', 22), ('local', 75), ('locat', 30), ('lock', 11), ('locker', 4), ('log', 15), ('logic', 20), ('logiccampclarksonedu', 2), ('login', 17), ('logistician', 5), ('loke', 3), ('london', 10), ('lone', 3), ('long', 82), ('longer', 16), ('longtim', 2), ('look', 253), ('loon', 4), ('loop', 15), ('loos', 9), ('lord', 2), ('lori', 11), ('lose', 38), ('loser', 9), ('loss', 16), ('lost', 50), ('lostweekend', 3), ('lot', 84), ('loui', 60), ('lousi', 5), ('love', 24), ('low', 21), ('lower', 6), ('lrw509f', 4), ('ls', 2), ('lsocket', 3), ('lu', 14), ('lucid', 5), ('luck', 13), ('lucki', 13), ('luddington', 2), ('ludicr', 3), ('lulea', 3), ('lunat', 5), ('lurk', 3), ('lx11', 2), ('lxext', 3), ('lxmu', 2), ('ly', 7), ('ma', 28), ('mac', 19), ('mac18', 5), ('macbigot', 2), ('macdonald', 3), ('mach', 1), ('machin', 82), ('macinni', 16), ('macintosh', 60), ('maciv', 4), ('maclean', 6), ('macro', 13), ('macx', 11), ('mafaldainriafr', 2), ('magazin', 6), ('magic', 4), ('magician', 3), ('magnifiqu', 3), ('magnusacsohiostateedu', 7), ('mahan', 22), ('mahi', 6), ('mail', 129), ('mailastcamacuk', 9), ('mailbox', 3), ('mailer', 14), ('mailhot', 3), ('mailsasupennedu', 28), ('mailtool', 4), ('main', 52), ('mainemaineedu', 3), ('mainli', 4), ('maintain', 19), ('mainwin', 5), ('major', 39), ('majorov', 5), ('mak', 4), ('makarov', 11), ('make', 33), ('makefil', 10), ('makela', 4), ('malabcca', 5), ('malarchuk', 12), ('malmo', 5), ('mamatha', 3), ('man', 51), ('manag', 210), ('mandatori', 3), ('mandir', 2), ('maniac', 2), ('manipul', 17), ('manner', 4), ('manon', 5), ('manretard', 5), ('manson', 6), ('manual', 40), ('manufactur', 7), ('map', 30), ('mapl', 28), ('mar', 1), ('marc', 8), ('march', 5), ('marco', 3), ('marcu', 7), ('mari', 8), ('marin', 4), ('mario', 50), ('maritim', 3), ('mark', 123), ('market', 13), ('marko', 5), ('marku', 5), ('markw', 2), ('marshal', 4), ('marti', 3), ('martin', 11), ('martinsvil', 4), ('martz', 4), ('marven', 3), ('mask', 46), ('mass', 3), ('massachusett', 4), ('massiv', 4), ('match', 32), ('matchup', 7), ('materi', 6), ('math', 11), ('mathemat', 9), ('matikainen', 2), ('matrix', 2), ('matt', 22), ('matteau', 3), ('matter', 28), ('matthew', 14), ('matthia', 3), ('matya', 5), ('max', 20), ('maximum', 10), ('maynard', 89), ('mb', 8), ('mc', 11), ('mccoi', 8), ('mcdonald', 4), ('mceachern', 7), ('mcgill', 14), ('mckee', 3), ('mckenzi', 3), ('mckim', 3), ('mclean', 7), ('mcnall', 4), ('mcphee', 6), ('mcrcimmcgilledu', 3), ('mcsore', 2), ('md', 9), ('mean', 101), ('meaningless', 6), ('meant', 6), ('measur', 8), ('mechan', 13), ('media', 9), ('mediamitedu', 5), ('medic', 4), ('mediocr', 7), ('medrautapplecom', 6), ('mee', 5), ('meet', 22), ('meg', 5), ('mehl', 7), ('melbourn', 3), ('mellanbi', 3), ('mellon', 9), ('melvil', 3), ('member', 16), ('memori', 93), ('men', 6), ('menschen', 3), ('mental', 6), ('mention', 43), ('menu', 35), ('menubar', 4), ('mere', 11), ('merit', 3), ('mess', 3), ('messag', 80), ('messier', 24), ('meta', 9), ('method', 30), ('metro', 6), ('metropolitan', 2), ('mfpirbo00wbli1ispc', 2), ('mgr', 3), ('mh', 16), ('mhung', 3), ('mhz', 3), ('mi', 10), ('miami', 7), ('mich', 2), ('micha', 3), ('michael', 46), ('michel', 6), ('michigan', 5), ('micro', 17), ('microsoft', 22), ('microsystem', 4), ('middl', 13), ('midwest', 3), ('mighti', 7), ('migod', 4), ('mike', 93), ('mikko', 7), ('mikkot', 4), ('mildli', 2), ('mile', 4), ('mileag', 2), ('militzok', 3), ('mill', 6), ('millen', 10), ('miller', 17), ('million', 16), ('milpita', 2), ('milton', 3), ('min', 31), ('mind', 41), ('mine', 9), ('minim', 5), ('minimum', 6), ('minn', 3), ('minnesota', 34), ('minor', 25), ('minorsrequest', 2), ('minu', 24), ('minut', 32), ('mip', 5), ('miracl', 4), ('mironov', 4), ('misc', 9), ('misconduct', 9), ('misfit', 4), ('mislead', 5), ('miss', 35), ('mission', 3), ('mistak', 9), ('misunderstand', 2), ('misus', 3), ('mit', 67), ('mitshm', 7), ('mix', 17), ('mjr4u', 3), ('mlindroo', 6), ('mmb', 5), ('mn', 6), ('mnemon', 2), ('mo', 8), ('modano', 3), ('mode', 38), ('model', 18), ('modem', 10), ('moder', 8), ('modicum', 2), ('modif', 6), ('modifi', 40), ('modo', 6), ('modul', 5), ('moepidoopend', 5), ('moffat', 5), ('mogilni', 24), ('mom', 3), ('mombasa', 3), ('moment', 14), ('momesso', 4), ('mon', 22), ('moncton', 11), ('mondai', 12), ('monei', 33), ('monica', 3), ('monitor', 24), ('mono', 19), ('monochrom', 25), ('month', 18), ('monthli', 3), ('monti', 2), ('montreal', 63), ('moog', 16), ('moor', 3), ('mopar', 3), ('morn', 9), ('moron', 16), ('morri', 5), ('moschetti', 3), ('mosquito', 3), ('motif', 278), ('motifbas', 8), ('motion', 4), ('motiv', 4), ('motorola', 6), ('mount', 7), ('mountain', 7), ('mous', 132), ('mouth', 4), ('move', 94), ('movi', 3), ('mppa3', 7), ('mprgatemprca', 1), ('mr47', 3), ('mre', 5), ('ms', 82), ('msc', 2), ('msdo', 15), ('msuinfoclmsuedu', 4), ('mswindow', 6), ('mt', 11), ('mtl', 28), ('mtroyalabca', 5), ('muckler', 4), ('mudvil', 3), ('mufti', 11), ('mule', 3), ('mullen', 20), ('muller', 9), ('multi', 3), ('multibyt', 5), ('multimedia', 12), ('multipart', 2), ('multipl', 55), ('multiscreen', 15), ('multithread', 4), ('munich', 6), ('murawski', 5), ('murphi', 27), ('murrai', 35), ('muscl', 5), ('music', 8), ('musicamcgillca', 3), ('musil', 4), ('mv', 6), ('mvp', 17), ('mwm', 24), ('mydisplai', 39), ('mysteri', 2), ('name', 189), ('namer', 3), ('nanci', 7), ('naoumov', 4), ('nasa', 7), ('nassestr', 2), ('nation', 33), ('natur', 9), ('navig', 3), ('nb', 3), ('nba', 7), ('nc', 5), ('ncaa', 4), ('ncd', 31), ('nchan', 3), ('ncr', 5), ('ncsuedu', 6), ('nd', 2), ('ne', 4), ('nearest', 3), ('nearli', 6), ('necessari', 10), ('necessarili', 7), ('neck', 6), ('nedv', 8), ('need', 197), ('neeli', 14), ('neg', 4), ('neglect', 4), ('negoti', 4), ('neil', 10), ('nelson', 17), ('neosoftcom', 6), ('nesbitt', 3), ('net', 77), ('netcomcom', 17), ('netherland', 8), ('netland', 3), ('netnewsupennedu', 5), ('netter', 10), ('network', 105), ('neural', 3), ('neutral', 6), ('new', 76), ('newcastleacuk', 2), ('newer', 5), ('newli', 2), ('newlin', 9), ('newscolumbiaedu', 5), ('newsdisplai', 1), ('newsgroup', 40), ('newshubistsca', 2), ('newspap', 3), ('nf', 9), ('nfl', 6), ('nh', 6), ('nhl', 164), ('nhler', 2), ('nhlpa', 3), ('nhma', 11), ('ni', 7), ('nice', 40), ('nichol', 7), ('nichola', 4), ('nick', 6), ('nicknam', 5), ('nieminen', 2), ('nieuwendyk', 14), ('night', 88), ('nimeroff', 3), ('nine', 2), ('ninja', 6), ('nj', 59), ('njd', 21), ('nkisseb', 2), ('nl', 3), ('nloraclecom', 6), ('nlu', 10), ('nne', 12), ('nntppostinghost', 5), ('node', 9), ('noncommerci', 3), ('nonsens', 8), ('nooseecnpurdueedu', 3), ('nord', 7), ('nordiqu', 6), ('norfolk', 5), ('normal', 31), ('norri', 37), ('north', 34), ('northland', 7), ('northwest', 3), ('norwai', 5), ('notabl', 5), ('note', 93), ('notebook', 5), ('noth', 50), ('notic', 38), ('notif', 3), ('notifyenablerpcsvc', 2), ('notion', 3), ('nov', 2), ('novactrcolumbiaedu', 2), ('novel', 16), ('novemb', 6), ('nowher', 3), ('nraoedu', 2), ('ns', 7), ('ns1cclehighedu', 5), ('nt', 31), ('nti', 3), ('nui', 4), ('nuktageopubcca', 3), ('null', 83), ('number', 126), ('numer', 6), ('numlock', 14), ('numminen', 9), ('ny', 54), ('nye', 9), ('nyi', 41), ('nyland', 11), ('nyr', 27), ('nystrom', 7), ('o2', 9), ('oak', 5), ('oat', 12), ('ob', 6), ('obfusc', 22), ('object', 58), ('objectori', 5), ('oblig', 10), ('obnoxi', 3), ('obscur', 8), ('obselet', 3), ('observ', 16), ('obsolet', 4), ('obtain', 33), ('obviou', 11), ('obvious', 16), ('occasion', 3), ('occass', 2), ('occur', 10), ('oclock', 3), ('octal', 3), ('octopu', 8), ('odd', 7), ('oddjobuchicagoedu', 4), ('odger', 11), ('odincontrolutorontoca', 3), ('odincorpsgicom', 3), ('odt', 5), ('offenc', 3), ('offend', 3), ('offens', 32), ('offer', 88), ('offic', 40), ('offici', 15), ('offseason', 5), ('offset', 3), ('ogrodnick', 5), ('oh', 35), ('ohio', 2), ('oi', 8), ('oiler', 48), ('oj', 4), ('ojala', 3), ('ok', 32), ('okai', 17), ('oklahoma', 4), ('ol', 13), ('olchowi', 32), ('old', 44), ('older', 5), ('olit', 20), ('oliv', 5), ('olvwm', 8), ('olwm', 23), ('olymp', 6), ('om', 4), ('omit', 1), ('on', 429), ('onlin', 9), ('ontario', 15), ('oop', 3), ('open', 171), ('opengl', 3), ('openlook', 22), ('openwin', 3), ('openwindow', 66), ('openwindowskeyboardcommand', 4), ('openwindowsvirtualgrabkei', 3), ('oper', 81), ('opinion', 54), ('oppon', 9), ('opportun', 20), ('opportunitiesmapl', 3), ('oppos', 13), ('opposit', 5), ('optim', 6), ('option', 53), ('ora', 3), ('oraclescghaccom', 3), ('oracom', 7), ('orang', 2), ('oranienburg', 3), ('order', 60), ('ordinari', 2), ('org', 2), ('organ', 27), ('orgin', 2), ('orient', 6), ('origin', 30), ('origon', 2), ('orr', 5), ('orunibonnd', 2), ('os', 61), ('osf', 33), ('osforg', 5), ('ot', 29), ('otherrealm', 2), ('ott', 14), ('ottawa', 32), ('otto', 12), ('ou', 3), ('ousrvroulufi', 3), ('outlaw', 4), ('outlin', 8), ('output', 165), ('outset', 3), ('outsid', 27), ('overachiev', 3), ('overal', 6), ('overhead', 8), ('overlai', 3), ('overlap', 4), ('overnight', 4), ('overrid', 16), ('overtim', 37), ('overview', 6), ('ow', 13), ('owen', 7), ('own', 5), ('owner', 16), ('oz', 5), ('ozplymouthedu', 5), ('pa', 8), ('pacif', 20), ('pack', 7), ('packag', 53), ('packard', 6), ('packet', 19), ('pad', 7), ('page', 42), ('pageup', 5), ('pageview', 7), ('pai', 16), ('paid', 11), ('pain', 7), ('paint', 12), ('pair', 4), ('palyer', 2), ('pan', 7), ('panel', 6), ('paper', 20), ('papercut', 3), ('paragraph', 3), ('paramet', 14), ('paramount', 3), ('paranjap', 3), ('parcplac', 6), ('pardon', 2), ('parent', 19), ('pari', 5), ('park', 8), ('pars', 31), ('part', 93), ('partial', 3), ('particip', 5), ('particular', 25), ('particularli', 11), ('pasi', 2), ('paslawski', 8), ('pass', 48), ('password', 3), ('past', 37), ('pat', 35), ('patch', 65), ('patchlevel', 1), ('path', 22), ('pathet', 3), ('patrick', 54), ('patrik', 2), ('pattern', 6), ('patti', 3), ('patton', 6), ('paul', 50), ('pavel', 4), ('paw', 3), ('pc', 87), ('pcnf', 10), ('pd', 7), ('pearson', 4), ('pelkei', 5), ('pen', 95), ('penalti', 85), ('pend', 2), ('penguin', 86), ('penn', 3), ('penni', 2), ('pensdevil', 1), ('penzingerstr', 5), ('peopl', 133), ('pera', 2), ('percentag', 17), ('perfect', 7), ('perform', 42), ('period', 212), ('perl', 1), ('perman', 1), ('permiss', 7), ('permit', 6), ('persist', 3), ('person', 69), ('personnel', 2), ('perspect', 3), ('pete', 9), ('peter', 27), ('peterrclarkjr', 2), ('petit', 1), ('petrilli', 2), ('petteri', 5), ('pex', 20), ('pftb', 3), ('pg', 2), ('pgh', 20), ('phi', 18), ('phig', 6), ('phil', 23), ('philadelphia', 33), ('philip', 3), ('philli', 13), ('phillip', 3), ('phoenix', 7), ('phoenixoulufi', 7), ('phone', 52), ('phrase', 3), ('physic', 8), ('physicssuozau', 2), ('physicsuncedu', 2), ('pick', 71), ('pictur', 12), ('pie', 9), ('piec', 9), ('pierr', 7), ('pig', 5), ('pim', 11), ('pine', 11), ('pipe', 18), ('pirat', 5), ('piss', 17), ('pit', 28), ('piti', 4), ('pitt', 40), ('pittedu', 15), ('pittsburg', 2), ('pittsburgh', 124), ('pixel', 29), ('pixmap', 69), ('pixrect', 3), ('pkortela', 4), ('pl', 4), ('place', 64), ('placement', 7), ('plagu', 5), ('plai', 401), ('plain', 10), ('plan', 11), ('plane', 19), ('platform', 23), ('platter', 3), ('playback', 3), ('player', 323), ('playoff', 190), ('pleas', 150), ('pleasant', 3), ('plenti', 4), ('pleshar', 4), ('plot', 11), ('plotter', 1), ('plp', 3), ('plscom', 4), ('plu', 46), ('plugger', 12), ('plural', 1), ('pm', 12), ('pmartz', 7), ('po', 32), ('pocklington', 16), ('pocwruedu', 6), ('podein', 4), ('point', 159), ('pointer', 32), ('polarisutufi', 4), ('polic', 2), ('polici', 6), ('polisciumnedu', 7), ('polit', 6), ('poll', 14), ('pond', 5), ('pont', 4), ('pool', 15), ('poor', 10), ('poorli', 3), ('poot', 3), ('pop', 13), ('poppsuedu', 3), ('popul', 7), ('popular', 14), ('popup', 8), ('porklington', 3), ('port', 38), ('portabl', 11), ('portion', 7), ('portland', 6), ('posit', 55), ('posn', 6), ('possibl', 93), ('post', 148), ('postal', 2), ('poster', 12), ('postscript', 56), ('postseason', 3), ('potenti', 7), ('potvin', 34), ('poulin', 7), ('pound', 4), ('power', 97), ('powerhous', 2), ('powerplai', 22), ('pp', 120), ('pposit', 11), ('ppv', 8), ('pr', 4), ('practic', 9), ('prai', 2), ('prais', 3), ('preced', 2), ('precis', 4), ('predict', 33), ('preempt', 5), ('prefer', 37), ('prentic', 2), ('prepaimitedu', 2), ('prepar', 4), ('presenc', 3), ('present', 28), ('preserv', 4), ('presid', 18), ('press', 47), ('pressur', 7), ('presum', 7), ('pretend', 3), ('pretti', 41), ('prevent', 13), ('preview', 7), ('previou', 31), ('previous', 8), ('price', 60), ('primari', 2), ('primarili', 6), ('prime', 10), ('primeau', 6), ('princeton', 3), ('print', 31), ('printer', 8), ('printf', 72), ('prior', 18), ('prioriti', 3), ('prismgatechedu', 16), ('pritchard', 2), ('prize', 4), ('pro', 15), ('probabl', 82), ('probert', 31), ('problem', 227), ('proce', 3), ('procedur', 12), ('proceed', 2), ('process', 67), ('processor', 5), ('proclaim', 3), ('produc', 40), ('product', 69), ('profession', 9), ('prog', 10), ('program', 329), ('programm', 38), ('programmat', 3), ('progress', 6), ('project', 18), ('prolog', 5), ('promis', 7), ('promot', 4), ('prompt', 11), ('prop', 3), ('propag', 2), ('proper', 10), ('properli', 11), ('properti', 19), ('proprietari', 5), ('propuls', 3), ('prospect', 6), ('protect', 7), ('protest', 2), ('protocol', 48), ('prototyp', 2), ('proud', 4), ('prove', 19), ('proven', 6), ('provid', 94), ('ps', 30), ('pseudo', 5), ('pseudocolor', 10), ('psize', 10), ('pspmf3gpsemicom', 2), ('psuvmpsuedu', 15), ('psv', 3), ('pt', 85), ('pub', 66), ('public', 43), ('publicli', 5), ('publish', 18), ('puck', 62), ('pucker', 3), ('pulford', 5), ('pull', 23), ('pulldown', 4), ('pumpkin', 3), ('punch', 5), ('purchas', 5), ('purdu', 6), ('pure', 10), ('purpos', 16), ('push', 15), ('put', 108), ('putimag', 2), ('pwd', 1), ('pwrop', 3), ('pyeatt', 12), ('pyramid', 3), ('quaker', 13), ('qualifi', 3), ('qualiti', 15), ('qualix', 3), ('quantifi', 3), ('quarter', 4), ('quarterdeck', 7), ('que', 29), ('quebec', 44), ('quebecmontr', 4), ('queloz', 10), ('queri', 9), ('question', 128), ('queue', 5), ('quick', 8), ('quickli', 10), ('quiet', 3), ('quietli', 2), ('quin', 5), ('quinn', 15), ('quit', 57), ('quot', 16), ('qwk', 3), ('r3', 9), ('r4', 40), ('r5', 64), ('r6', 4), ('race', 19), ('radio', 16), ('rag', 5), ('ragraca', 7), ('rai', 23), ('raider', 3), ('rain', 14), ('rainbowecnpurdueedu', 5), ('rainer', 31), ('rainout', 3), ('rais', 9), ('ralph', 19), ('ram', 5), ('rambl', 3), ('ramblerengsuncom', 5), ('ramsei', 4), ('ramseycslaurentianca', 55), ('ran', 5), ('rand', 5), ('randi', 26), ('randolin', 4), ('random', 9), ('ranford', 5), ('rang', 9), ('ranger', 108), ('ranheim', 4), ('rank', 8), ('ranlib', 2), ('rant', 4), ('rap115', 12), ('rapidli', 3), ('rare', 9), ('raster', 7), ('rate', 29), ('ratnam', 3), ('rauser', 8), ('rd', 5), ('reach', 8), ('reaction', 4), ('read', 114), ('reader', 9), ('readi', 10), ('readm', 7), ('readonli', 8), ('real', 54), ('realist', 4), ('realiti', 7), ('realiz', 24), ('realli', 143), ('realtim', 8), ('reap', 2), ('reason', 64), ('rebound', 11), ('recal', 16), ('recchi', 12), ('receiv', 55), ('recent', 33), ('reclaim', 2), ('recogn', 8), ('recognis', 5), ('recommend', 31), ('recompil', 6), ('record', 50), ('recov', 6), ('recsporthockei', 15), ('rectangl', 15), ('rectifi', 2), ('red', 64), ('redefin', 2), ('redirect', 8), ('redistribut', 5), ('redlin', 3), ('redraw', 14), ('redrawn', 1), ('reduc', 9), ('redw', 5), ('redwood', 4), ('ref', 13), ('refer', 31), ('refere', 13), ('referenc', 6), ('reflect', 3), ('refresh', 4), ('refus', 6), ('regard', 20), ('regardless', 2), ('region', 8), ('regist', 14), ('registri', 7), ('regress', 4), ('regular', 37), ('regularli', 7), ('regularseason', 5), ('reichel', 11), ('reilli', 32), ('reinvent', 1), ('reject', 2), ('rel', 11), ('relai', 3), ('relat', 19), ('relationship', 3), ('releas', 53), ('relev', 9), ('reli', 4), ('reluct', 3), ('remain', 17), ('remap', 7), ('remark', 35), ('rememb', 62), ('remind', 7), ('remot', 41), ('remov', 19), ('renam', 3), ('render', 18), ('renegad', 3), ('reno', 2), ('rent', 7), ('rep', 2), ('repeat', 10), ('replac', 27), ('replai', 12), ('repli', 40), ('repo', 3), ('report', 35), ('repost', 10), ('repres', 19), ('represent', 4), ('republ', 4), ('republican', 3), ('request', 74), ('requir', 81), ('research', 29), ('resembl', 6), ('resent', 3), ('reserv', 12), ('reset', 5), ('resid', 6), ('resign', 6), ('resiz', 11), ('resolut', 13), ('resolv', 4), ('resort', 3), ('resourc', 64), ('respect', 15), ('respond', 31), ('respons', 43), ('rest', 28), ('restart', 3), ('restor', 8), ('restrict', 6), ('result', 67), ('ret', 9), ('retain', 1), ('retir', 10), ('retriev', 7), ('return', 103), ('reveng', 6), ('revers', 4), ('review', 20), ('revis', 6), ('reward', 3), ('rewrit', 4), ('rewritten', 3), ('rex', 11), ('rgasch', 6), ('rgooch', 5), ('rheaum', 5), ('ricci', 3), ('rich', 10), ('richard', 47), ('richardson', 16), ('richer', 3), ('rick', 39), ('rid', 8), ('ride', 4), ('ridicul', 9), ('riendeau', 3), ('riga', 3), ('right', 122), ('riihijarvi', 4), ('rinaco', 3), ('rindex', 2), ('ring', 12), ('rink', 11), ('risebrough', 4), ('rivalri', 3), ('rl', 4), ('rlogin', 9), ('rm', 30), ('road', 13), ('roadrunn', 4), ('roam', 5), ('rob', 24), ('robb', 4), ('robbi', 16), ('robert', 52), ('robertson', 3), ('robitail', 19), ('robyn', 3), ('rochest', 17), ('rock', 10), ('rocker', 3), ('rocket', 6), ('rocki', 3), ('rod', 7), ('roenick', 15), ('rog', 5), ('roger', 92), ('roi', 16), ('role', 8), ('roll', 7), ('rom', 2), ('roman', 9), ('romulusmathjyufi', 4), ('ron', 65), ('ronald', 8), ('ronni', 2), ('rooki', 13), ('room', 11), ('root', 35), ('rootwindow', 8), ('rose', 2), ('rosecom', 4), ('rosevcrosehulmanedu', 3), ('rospach', 6), ('ross', 7), ('roster', 9), ('rotat', 18), ('rotten', 4), ('rough', 20), ('roughli', 5), ('round', 55), ('rout', 11), ('routin', 22), ('row', 14), ('royal', 2), ('rp', 4), ('rp16', 4), ('rpc', 8), ('rpcsiroau', 4), ('rpiedu', 8), ('rs', 17), ('rsh', 24), ('rub', 2), ('rubberband', 4), ('ruin', 4), ('rule', 50), ('rumor', 13), ('rumour', 5), ('run', 294), ('runtim', 10), ('rush', 9), ('russia', 5), ('russian', 15), ('rutger', 5), ('rutgersrochesterferguson', 3), ('ruuttu', 4), ('rw', 7), ('ryan', 7), ('rychel', 10), ('sa', 5), ('saad', 5), ('sabr', 54), ('sad', 12), ('safe', 6), ('sai', 66), ('saint', 16), ('sakari', 2), ('sake', 4), ('sakic', 3), ('salami', 5), ('salari', 3), ('sale', 24), ('salmon', 6), ('salvator', 6), ('sam', 15), ('sambaoituncedu', 3), ('sampl', 19), ('samuel', 4), ('samuelson', 8), ('samuelsson', 5), ('san', 69), ('sander', 4), ('sanderson', 22), ('sandi', 3), ('sandstrom', 16), ('santa', 15), ('sarcasm', 5), ('saskatchewan', 3), ('sat', 2), ('satan', 4), ('satellit', 2), ('sather', 4), ('satisfi', 3), ('saturdai', 7), ('savard', 19), ('save', 77), ('saw', 21), ('sc', 9), ('sca', 9), ('scalabl', 7), ('scale', 17), ('scan', 5), ('schedul', 34), ('scheme', 14), ('schietk', 8), ('schneider', 2), ('schock', 4), ('school', 21), ('schot', 3), ('scienc', 44), ('scientif', 4), ('sco', 36), ('scoop', 2), ('score', 167), ('scorer', 59), ('scott', 43), ('scotti', 3), ('scr', 14), ('scratch', 6), ('screen', 127), ('screw', 11), ('script', 18), ('scroll', 1), ('scrollbar', 4), ('sd', 4), ('se05wg2waiicom', 7), ('seal', 3), ('seamen', 3), ('sean', 3), ('search', 8), ('season', 137), ('seat', 13), ('seattl', 5), ('sec', 2), ('second', 128), ('secondli', 3), ('section', 46), ('secur', 8), ('sed', 2), ('sedonaintelcom', 4), ('see', 213), ('seemingli', 3), ('seen', 54), ('segment', 12), ('seguin', 3), ('seicmuedu', 12), ('sel', 12), ('selann', 53), ('select', 33), ('self', 8), ('selfish', 3), ('selk', 11), ('sell', 25), ('sellout', 2), ('semak', 3), ('semant', 3), ('semi', 4), ('semiconductor', 6), ('semifin', 10), ('senat', 20), ('send', 128), ('senior', 6), ('sens', 5), ('senseless', 3), ('sent', 22), ('separ', 11), ('seppo', 3), ('septemb', 4), ('sequenc', 24), ('serg', 4), ('sergei', 5), ('seri', 98), ('serial', 23), ('seriou', 6), ('serious', 12), ('serv', 11), ('server', 296), ('servic', 35), ('session', 31), ('set', 201), ('setenv', 6), ('seth', 9), ('settl', 17), ('setup', 25), ('seven', 10), ('sfuca', 6), ('sfwa', 2), ('sg', 5), ('sgi', 17), ('sgicom', 3), ('sh', 31), ('shade', 10), ('shadow', 8), ('shall', 2), ('shame', 4), ('shanahan', 15), ('shannon', 5), ('shape', 23), ('share', 52), ('sharewar', 7), ('shark', 47), ('sharksrequest', 2), ('sharp', 3), ('shawn', 4), ('shear', 3), ('sheffield', 4), ('sheffieldhallamacuk', 3), ('shell', 42), ('shellscript', 2), ('shelltool', 3), ('sheppard', 5), ('shift', 28), ('shine', 5), ('ship', 22), ('shit', 14), ('shjon', 2), ('shneyder', 11), ('shoot', 20), ('shooter', 1), ('shop', 2), ('short', 15), ('shortcut', 2), ('shorthand', 8), ('shot', 129), ('shoulder', 5), ('shovel', 3), ('show', 185), ('shown', 20), ('shut', 7), ('shutdown', 2), ('shutout', 8), ('si', 4), ('sic', 7), ('sick', 7), ('side', 36), ('siemen', 4), ('sig', 4), ('sigh', 4), ('sight', 3), ('sigmakpccom', 7), ('sign', 21), ('signal', 11), ('signific', 14), ('significantli', 2), ('silent', 1), ('silli', 5), ('silver', 4), ('similar', 34), ('similarli', 3), ('simmonac', 3), ('simon', 4), ('simpl', 40), ('simpler', 3), ('simpli', 32), ('simplifi', 2), ('simul', 7), ('simulog', 2), ('simultan', 6), ('sincerest', 3), ('singl', 34), ('sisko', 3), ('sit', 7), ('site', 41), ('sittler', 7), ('situat', 19), ('six', 17), ('size', 79), ('sizeof', 6), ('sj', 20), ('skate', 41), ('skateless', 3), ('skater', 5), ('skidmoreedu', 2), ('skill', 23), ('skin', 6), ('skip', 14), ('skipjack', 4), ('skriko', 3), ('skrudland', 12), ('slap', 6), ('slash', 13), ('slateminescoloradoedu', 3), ('sleep', 12), ('slide', 7), ('slightli', 2), ('slime', 3), ('slip', 9), ('slot', 14), ('slovakia', 3), ('slow', 14), ('slower', 11), ('slump', 4), ('smale', 10), ('small', 21), ('smaller', 5), ('smart', 7), ('smarter', 2), ('smash', 3), ('smeghead', 3), ('smehlik', 6), ('smilei', 4), ('smith', 39), ('smithw', 4), ('smorri', 4), ('smsbusinessuwoca', 10), ('smtp', 4), ('smyth', 34), ('snail', 5), ('snakemailhutfi', 4), ('snell', 3), ('snyder', 2), ('socal', 3), ('sock', 3), ('socket', 15), ('sod', 3), ('soderstrom', 3), ('soft', 5), ('softwar', 171), ('solari', 23), ('solbourn', 6), ('solctrcolumbiaedu', 4), ('sold', 9), ('soldier', 3), ('solid', 11), ('solut', 31), ('soluvicca', 7), ('solv', 9), ('somebodi', 22), ('somehow', 14), ('someon', 84), ('someth', 104), ('sometim', 13), ('somewhat', 6), ('somewher', 13), ('son', 5), ('soon', 28), ('sooner', 2), ('sooooo', 3), ('sophiainriafr', 3), ('sophist', 4), ('sorri', 28), ('sort', 22), ('soul', 6), ('sound', 23), ('sourc', 126), ('south', 14), ('southern', 5), ('souvien', 6), ('sp', 9), ('space', 67), ('spangcamosunbcca', 3), ('sparc', 53), ('sparc1ottawajadecom', 3), ('sparcstat', 11), ('spawn', 5), ('speak', 19), ('spear', 2), ('spec', 8), ('special', 31), ('specif', 44), ('specifi', 38), ('spectacular', 3), ('spectat', 5), ('speed', 16), ('speedup', 2), ('spell', 3), ('spend', 10), ('spent', 10), ('spew', 2), ('spike', 4), ('spinal', 3), ('spirit', 7), ('split', 7), ('spoil', 3), ('sponsor', 11), ('spool', 3), ('sport', 46), ('sportscast', 4), ('sportscent', 1), ('sportschannel', 10), ('spot', 9), ('spread', 2), ('spreadsheet', 5), ('spring', 3), ('springfield', 9), ('sprintf', 4), ('spud', 3), ('sqcom', 6), ('sqsqcom', 2), ('squar', 2), ('squat', 2), ('squeez', 6), ('sr', 10), ('src', 6), ('ssdkodakcom', 3), ('st', 69), ('stabl', 3), ('stack', 9), ('stadium', 5), ('staff', 3), ('staffan', 16), ('stage', 3), ('stai', 28), ('stamber', 15), ('stan', 10), ('stand', 46), ('standard', 84), ('standarddisclaim', 3), ('stane', 3), ('stanford', 3), ('stanlei', 58), ('star', 53), ('starbasespdlouisvilleedu', 3), ('start', 143), ('startidectrcolumbiaedu', 3), ('startup', 18), ('stat', 68), ('state', 64), ('statement', 12), ('stath', 3), ('stati', 1), ('static', 34), ('staticcolor', 4), ('station', 18), ('statist', 10), ('statu', 15), ('stderr', 33), ('stdin', 21), ('stdioh', 4), ('stdout', 8), ('steadi', 5), ('steal', 2), ('steel', 5), ('steen', 5), ('stefan', 4), ('stein', 9), ('step', 9), ('stephan', 4), ('stephen', 12), ('stern', 6), ('steve', 55), ('steveg', 8), ('steven', 38), ('stevenkipl', 4), ('stewart', 5), ('stick', 40), ('sticknot', 2), ('stiehm', 13), ('stimpi', 6), ('stink', 2), ('stl', 33), ('stloui', 5), ('stockholm', 13), ('stop', 4), ('storag', 12), ('store', 23), ('stori', 8), ('storm', 6), ('stormchas', 3), ('stplistsca', 17), ('straight', 20), ('strang', 7), ('strategi', 12), ('streak', 6), ('stream', 61), ('street', 12), ('stress', 3), ('strictli', 2), ('stride', 3), ('strike', 3), ('string', 67), ('strip', 9), ('stripe', 6), ('strlen', 5), ('stroke', 3), ('strong', 16), ('stronger', 5), ('strongli', 3), ('struct', 6), ('structur', 14), ('structurenotifymask', 2), ('struggl', 3), ('stryker', 3), ('stty', 4), ('stuart', 8), ('stuck', 13), ('student', 11), ('studentbusinessuwoca', 4), ('studi', 10), ('studio', 4), ('stuff', 52), ('stupid', 28), ('stuppid', 3), ('style', 28), ('subclass', 4), ('subdir', 6), ('subject', 959), ('submiss', 4), ('submit', 10), ('subroutin', 3), ('subscrib', 28), ('subscript', 5), ('subset', 3), ('success', 13), ('successfulli', 4), ('suck', 16), ('sudden', 3), ('suddenli', 6), ('suffer', 10), ('suffici', 12), ('suggest', 55), ('suhonen', 9), ('suit', 23), ('suitabl', 3), ('suke', 3), ('sullivan', 8), ('sum', 3), ('summar', 6), ('summari', 27), ('summer', 4), ('sun', 181), ('sun3', 16), ('sun3eeamelincoat', 7), ('sun4', 5), ('sunbimb', 4), ('suncom', 6), ('sundai', 19), ('sundin', 3), ('sundog', 3), ('sunnyval', 6), ('suno', 39), ('sunsoft', 6), ('sunview', 23), ('superior', 7), ('superiorcarletonca', 4), ('superstar', 7), ('supplement', 7), ('suppli', 16), ('support', 234), ('suppos', 23), ('supposedli', 3), ('sure', 114), ('suresh', 7), ('surpris', 29), ('surround', 2), ('survei', 3), ('surviv', 4), ('susan', 9), ('suspect', 4), ('suspens', 4), ('sussex', 3), ('suter', 15), ('sutherland', 4), ('sutter', 16), ('sv', 6), ('svga', 9), ('svr4', 8), ('swap', 3), ('swartzjh', 3), ('swe', 4), ('swear', 4), ('swede', 4), ('sweden', 20), ('swedish', 7), ('sweenei', 9), ('sweep', 14), ('sweet', 3), ('swick', 6), ('swillbelli', 3), ('switch', 30), ('switzerland', 8), ('sy', 25), ('sydnei', 5), ('symasussexacuk', 6), ('symbol', 27), ('symlink', 3), ('synopticscom', 9), ('syntax', 3), ('synthet', 3), ('sysadministr', 4), ('system', 292), ('sysv', 5), ('sysvr4', 2), ('ta', 7), ('tab', 5), ('tabaracci', 4), ('tabl', 29), ('tactic', 2), ('tag', 3), ('take', 133), ('taken', 13), ('taker', 3), ('talant', 3), ('talent', 36), ('talk', 52), ('talon', 3), ('tampa', 21), ('tamper', 3), ('tap', 6), ('tape', 33), ('tapedelai', 6), ('tapio', 3), ('tappara', 4), ('tar', 4), ('target', 13), ('tarkiainen', 4), ('tarz', 3), ('task', 8), ('tast', 2), ('taught', 3), ('tauruscsnpsnavymil', 4), ('tax', 3), ('taylor', 16), ('tayloruucp', 12), ('tb', 26), ('tba', 5), ('tbd', 2), ('tbl', 7), ('tcl', 7), ('tcp', 104), ('td', 3), ('teach', 2), ('tealcsnorg', 6), ('tealengsuncom', 3), ('team', 470), ('tear', 6), ('tech', 7), ('technic', 50), ('technolog', 34), ('ted', 9), ('tee', 6), ('teem', 3), ('teemu', 7), ('teh', 3), ('tek', 4), ('tekeleccom', 4), ('tektronix', 9), ('tel', 59), ('telecast', 15), ('telecom', 10), ('telefax', 5), ('telephon', 9), ('telesoftcom', 5), ('teleus', 6), ('televis', 16), ('telex', 3), ('tell', 88), ('telnet', 16), ('temp', 2), ('templat', 3), ('temporari', 3), ('temporarili', 5), ('tend', 9), ('tent', 2), ('teppo', 2), ('term', 42), ('termcap', 2), ('termin', 88), ('terminolog', 2), ('terri', 4), ('terribl', 9), ('test', 40), ('tex', 3), ('texa', 11), ('texacocom', 7), ('text', 85), ('tgif', 4), ('tgv', 8), ('tgvcom', 13), ('th', 4), ('thank', 212), ('thanx', 12), ('thelik', 2), ('theori', 6), ('thin', 4), ('thing', 138), ('think', 286), ('third', 67), ('thoma', 29), ('thorn', 8), ('thought', 54), ('thread', 11), ('threat', 3), ('three', 53), ('threw', 5), ('thrill', 3), ('throw', 18), ('thrown', 9), ('thu', 6), ('thumb', 12), ('thunder', 5), ('thundermcrcimmcgilledu', 5), ('thursdai', 22), ('ti', 28), ('tichonov', 7), ('ticket', 14), ('tickl', 4), ('tie', 41), ('tiebreak', 6), ('tiff', 5), ('tiger', 7), ('tight', 4), ('tikkanen', 2), ('tikkannen', 5), ('til', 3), ('till', 4), ('tim', 23), ('time', 318), ('timeout', 7), ('timer', 6), ('timo', 6), ('timothi', 3), ('tini', 3), ('tip', 7), ('tippett', 6), ('titl', 62), ('tk', 5), ('tkachuk', 7), ('tm', 20), ('tmp', 1), ('tn', 5), ('tnt', 5), ('tobia', 5), ('tocchet', 22), ('todai', 27), ('todd', 6), ('toe', 3), ('toi', 3), ('told', 14), ('tom', 61), ('tommi', 18), ('tomorrow', 2), ('ton', 2), ('tonelli', 6), ('tonight', 23), ('tonit', 3), ('took', 42), ('tool', 68), ('toolkit', 83), ('tooltalk', 5), ('top', 72), ('topic', 25), ('toplevel', 29), ('tor', 43), ('toronto', 73), ('total', 35), ('touch', 6), ('tough', 23), ('tougher', 6), ('toughest', 2), ('tournament', 11), ('town', 9), ('tp', 9), ('tr', 5), ('trace', 6), ('track', 10), ('trade', 75), ('tradit', 6), ('traffic', 6), ('trail', 6), ('train', 15), ('transfer', 12), ('transform', 8), ('transit', 3), ('translat', 25), ('transpar', 12), ('transplant', 3), ('transport', 8), ('trash', 5), ('travel', 3), ('treat', 3), ('tree', 7), ('trehguad', 3), ('trend', 3), ('trevor', 7), ('tri', 49), ('triangl', 3), ('trick', 9), ('trickster', 3), ('trident', 5), ('trip', 13), ('trivia', 11), ('troff', 2), ('troi', 5), ('trophi', 13), ('trottier', 7), ('troubl', 19), ('truck', 3), ('true', 64), ('truecolor', 14), ('truli', 12), ('trumpet', 3), ('trust', 6), ('truth', 3), ('try', 128), ('ts', 10), ('tsn', 7), ('tty', 11), ('tue', 5), ('tuesdai', 16), ('tuft', 3), ('tune', 3), ('turcott', 5), ('turgeon', 15), ('turkei', 3), ('turku', 4), ('turn', 31), ('turner', 18), ('turtl', 6), ('tutori', 33), ('tv', 24), ('tvartiai', 5), ('tvtwm', 28), ('tvtwmrc', 3), ('tweak', 3), ('twice', 8), ('twm', 33), ('twmrc', 3), ('two', 173), ('twowai', 8), ('tx', 9), ('ty', 2), ('type', 78), ('typesh', 3), ('typic', 22), ('u013mevpcom', 5), ('ua256', 4), ('ub', 3), ('ubvmsccbuffaloedu', 10), ('ubvmsdccbuffaloedu', 4), ('ucb', 1), ('ucbvaxuwvaxastroatcftmsbrown', 3), ('ufsaericssons', 9), ('ugli', 6), ('ui', 9), ('uil', 4), ('uim', 6), ('uit', 4), ('uiucedu', 3), ('uk', 24), ('ulf', 35), ('ulfi', 1), ('ultim', 6), ('ultrix', 14), ('um', 3), ('umain', 2), ('umpir', 3), ('umturne4', 10), ('unabl', 11), ('unassist', 17), ('unbca', 3), ('unbeliev', 3), ('unchang', 3), ('uncompress', 2), ('undef', 3), ('undefin', 25), ('underachiev', 6), ('undergradmathuwaterlooca', 5), ('underli', 4), ('underneath', 3), ('understand', 24), ('undoubtedli', 1), ('unfortun', 22), ('uniform', 4), ('uniqu', 3), ('unit', 17), ('unitasorunibonnd', 2), ('univ', 9), ('univers', 99), ('unix', 89), ('unknown', 7), ('unnecessari', 4), ('unnecessarili', 5), ('unoffici', 3), ('unpack', 3), ('unsign', 7), ('unsportsmanlik', 3), ('unsubscrib', 4), ('unsur', 3), ('unusu', 3), ('unwil', 3), ('upcom', 7), ('updat', 47), ('upgrad', 8), ('upper', 5), ('upset', 7), ('uptod', 3), ('us', 79), ('usa', 45), ('usag', 14), ('useless', 5), ('usenet', 28), ('user', 175), ('usernam', 2), ('usposit', 5), ('usr', 50), ('ussiz', 4), ('usual', 36), ('utica', 6), ('util', 29), ('utilo', 4), ('utter', 3), ('uu2psicomftmsbrown', 3), ('uucp', 20), ('uudecod', 2), ('uunet', 12), ('uunetuunet', 15), ('uw', 3), ('ux', 4), ('uxacsouiucedu', 3), ('v085pwpz', 7), ('v212', 3), ('v3', 2), ('va', 6), ('vacat', 4), ('vaiv', 4), ('val', 11), ('valeri', 24), ('valid', 13), ('vallei', 3), ('valu', 65), ('valuabl', 10), ('van', 56), ('vanbiesbrouck', 6), ('vancouv', 62), ('vancouveruvicca', 3), ('vanilla', 4), ('var', 3), ('vari', 7), ('variabl', 35), ('variant', 3), ('variat', 2), ('varieti', 15), ('variou', 25), ('vartiainen', 5), ('varvio', 3), ('vasili', 6), ('vax', 3), ('vaxcnsmuskingumedu', 6), ('vccsouth22itsrpiedu', 3), ('vegetarian', 3), ('vein', 3), ('velaacsoaklandedu', 13), ('vendor', 60), ('venuslercnasagov', 4), ('verbeek', 7), ('vergolin', 5), ('vergolini', 5), ('verifi', 9), ('vernon', 17), ('version', 196), ('versu', 6), ('veteran', 3), ('vezina', 4), ('vga', 26), ('vi', 5), ('viciou', 4), ('victim', 2), ('victor', 2), ('victori', 18), ('victoria', 3), ('video', 17), ('vidiot', 5), ('view', 35), ('viewer', 13), ('vincent', 10), ('violenc', 5), ('violent', 3), ('vipunenhutfi', 8), ('virden', 4), ('virginia', 3), ('virginiaedu', 6), ('virtual', 40), ('visibl', 9), ('vision', 3), ('visit', 2), ('vista', 4), ('visual', 50), ('visualcom', 6), ('vital', 4), ('vlad', 5), ('vladimir', 6), ('vm', 15), ('vm1mcgillca', 2), ('vmshujiacil', 5), ('voic', 25), ('void', 21), ('vol', 13), ('volum', 31), ('vomit', 3), ('von', 7), ('vote', 32), ('votenooct26', 3), ('vox', 4), ('voyageur', 3), ('vp', 5), ('vpbuildvpcom', 4), ('vs', 92), ('vsnhl', 3), ('vt100', 5), ('vtwm', 6), ('vue', 5), ('vuewm', 6), ('vzhivov', 6), ('wa', 5), ('wabcam', 3), ('waffl', 3), ('wai', 190), ('wait', 46), ('wake', 10), ('wale', 8), ('walk', 2), ('walker', 5), ('wall', 3), ('wallet', 2), ('walsh', 3), ('walter', 5), ('wamslei', 5), ('wang', 3), ('wangr', 6), ('want', 207), ('ward', 4), ('ware', 5), ('wariatorg', 4), ('warn', 39), ('warranti', 3), ('warren', 6), ('wash', 16), ('washer', 5), ('washington', 33), ('wast', 14), ('watch', 90), ('waterloo', 5), ('watserv1uwaterlooca', 3), ('wave', 7), ('wavefrontwticom', 5), ('wayn', 16), ('wc', 34), ('wcl', 10), ('weak', 7), ('wear', 9), ('weather', 2), ('wed', 4), ('wednesdai', 7), ('week', 65), ('weekend', 6), ('weigh', 3), ('weight', 12), ('weinrich', 8), ('weird', 6), ('welcom', 24), ('wellsi', 3), ('wemblei', 3), ('wendel', 6), ('went', 51), ('weslei', 3), ('wessel', 4), ('west', 18), ('western', 25), ('wg2waiicom', 3), ('wgep', 5), ('whack', 2), ('whalei', 15), ('whaler', 22), ('wheel', 1), ('whichev', 3), ('white', 32), ('whitepixel', 5), ('wholesal', 3), ('wide', 13), ('widefield', 3), ('widget', 262), ('width', 20), ('wien', 5), ('wiextrelcom', 3), ('wild', 4), ('wilkinson', 6), ('will', 10), ('willi', 14), ('william', 12), ('wilson', 12), ('wimp', 3), ('win', 243), ('wind', 4), ('window', 720), ('wing', 114), ('winger', 7), ('wingschevelda', 3), ('winner', 28), ('winnipeg', 56), ('winopen', 5), ('winsock', 4), ('winter', 7), ('wise', 4), ('wish', 15), ('wittysai', 3), ('wkuvx1bitnet', 10), ('wm', 13), ('wollongong', 10), ('wolv', 6), ('wombat', 3), ('women', 6), ('wonder', 42), ('wong', 10), ('wont', 3), ('wood', 22), ('woof', 7), ('woofer', 4), ('woosbag', 3), ('word', 49), ('wordprocessor', 5), ('worf', 3), ('work', 232), ('workaround', 4), ('workspac', 4), ('workstat', 22), ('world', 52), ('worldstdcom', 4), ('worldwid', 2), ('wormtown', 3), ('worri', 14), ('wors', 11), ('worst', 16), ('worth', 20), ('worthless', 8), ('wow', 8), ('wpg', 10), ('wpiwpiedu', 4), ('wrap', 7), ('wrist', 4), ('write', 483), ('writer', 6), ('written', 36), ('wrong', 58), ('wrote', 41), ('wrt', 1), ('wsh', 16), ('wueclwustledu', 4), ('ww1a', 5), ('x1', 6), ('x11', 121), ('x111', 2), ('x11r3', 6), ('x11r4', 67), ('x11r4base', 2), ('x11r5', 120), ('x11r5sos5', 5), ('x2', 6), ('x3', 2), ('x400', 4), ('xall', 1), ('xalloccolor', 5), ('xand', 1), ('xarchi', 5), ('xauthor', 4), ('xaw', 17), ('xbase', 25), ('xbiff', 2), ('xbm', 4), ('xcleararea', 7), ('xcopyarea', 8), ('xcopyplan', 8), ('xcopyright', 1), ('xcreatecolormap', 4), ('xcreategc', 8), ('xcreatesimplewindow', 5), ('xcreatewindow', 7), ('xdefault', 20), ('xdm', 38), ('xdmcp', 11), ('xdpyinfo', 3), ('xdrawlin', 8), ('xdvi', 1), ('xenonstanfordedu', 10), ('xenophob', 3), ('xevent', 7), ('xfaq', 3), ('xfig', 4), ('xfillrectangl', 4), ('xflush', 4), ('xfree86', 10), ('xgetimag', 7), ('xgrabkei', 5), ('xhibit', 22), ('xhost', 4), ('ximag', 12), ('xinclud', 5), ('xinitrc', 6), ('xkernel', 11), ('xlib', 92), ('xlibh', 3), ('xlookupstr', 5), ('xm', 15), ('xmail', 3), ('xmapwindow', 3), ('xmdrawingarea', 12), ('xmh', 9), ('xmndialogstyl', 3), ('xmodmap', 12), ('xmu', 17), ('xnew', 4), ('xnextev', 4), ('xol', 6), ('xon', 2), ('xopendisplai', 10), ('xopenwindow', 3), ('xor', 3), ('xpert', 9), ('xpm', 8), ('xputimag', 22), ('xrdb', 11), ('xremot', 17), ('xresourc', 2), ('xserver', 24), ('xserversnonunixtxtz', 3), ('xsession', 10), ('xsetforeground', 5), ('xsetfunct', 4), ('xsetroot', 9), ('xsetwindowattribut', 3), ('xsetwmnormalhint', 3), ('xsizehint', 23), ('xstorecolor', 5), ('xstuff', 14), ('xsun', 28), ('xsync', 2), ('xt', 74), ('xtaddcallback', 7), ('xtaddeventhandl', 8), ('xtappaddtimeout', 4), ('xtappcontext', 9), ('xtappiniti', 6), ('xtappmainloop', 4), ('xtbase', 8), ('xtc', 3), ('xtcreatemanagedwidget', 5), ('xtdestroywidget', 11), ('xtdispatchev', 3), ('xtdisplai', 16), ('xterm', 113), ('xtermin', 33), ('xtermvt100transl', 2), ('xtgetvalu', 3), ('xthe', 1), ('xtpointer', 11), ('xtra', 3), ('xtrealizewidget', 6), ('xtsetarg', 21), ('xtvacreatemanagedwidget', 7), ('xtvasetvalu', 3), ('xtwindow', 14), ('xtwindowofobject', 2), ('xusag', 1), ('xutilh', 3), ('xv', 50), ('xv300tarz', 3), ('xvertext', 8), ('xview', 93), ('xview3', 8), ('xvision', 8), ('xvisualinfo', 4), ('xvt', 7), ('xw', 5), ('xwd', 14), ('xwindow', 35), ('xwith', 1), ('xwud', 6), ('xx', 2), ('xy', 5), ('y1', 5), ('y2', 8), ('ya', 9), ('yadal', 3), ('yadalle', 7), ('yan', 3), ('yang', 6), ('yanke', 6), ('yawnei', 11), ('yeah', 18), ('year', 300), ('yell', 3), ('yellow', 4), ('yep', 4), ('yesterdai', 9), ('yield', 2), ('yl', 2), ('york', 26), ('young', 32), ('youngbuc', 3), ('younger', 6), ('ysebaert', 8), ('yzerman', 23), ('zachman', 3), ('zalapski', 4), ('zamun', 5), ('zcode', 3), ('zcodecom', 3), ('zelepukin', 9), ('zero', 9), ('zeta', 3), ('zezel', 3), ('zhamnov', 11), ('zhitnik', 7), ('zhivov', 6), ('zipper', 3), ('zombo', 9), ('zone', 25), ('zoom', 8), ('zubov', 9), ('zupanc', 3)]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-498571c98d50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdictTD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msortedTD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdictTD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0msortedTD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "#Put the frequencies together in a dictionary\n",
    "dictTD = {}\n",
    "for i in range(numterms_T):\n",
    "    dictTD[terms2[i]] = freqbyterm_int[i]\n",
    "print sorted(dictTD.items())\n",
    "sortedTD = sorted(dictTD.values(), reverse=True)\n",
    "print sortedTD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Classifier should allow training data matrix (TM), Training Lables (TL), Instance to be classified (x), and the value\n",
    "#of K\n",
    "#def knn_newsgroup(TM, TL, x, K):\n",
    "\n",
    "#This function takes an instance to be searched for (x) - vector\n",
    "#Then it takes your document x term matrix (D)\n",
    "#K Specifies your number of neighbors (K)\n",
    "#Measure - if set to 0 you are using Euclidean, set to 1 you use the inverse of Cosine similarity\n",
    "def knn_search(x, D, K, measure):\n",
    "    \n",
    "    if measure == 0:\n",
    "        #euclidean distance from other points - subtract x from each row in D, take the sum of the squares, and use the \n",
    "        #square root - axis = 1 here because we are adding up all the terms\n",
    "        dists = np.sqrt(((D - x)**2).sum(axis=1))\n",
    "        \n",
    "    elif measure == 1:\n",
    "        #find vector norm in each instance in D as well as the vecotr norm of x\n",
    "        #Cosine similarity is the dot product divided by the multiple of the norms\n",
    "        #D_norm = normalized vectors of D (all rows)\n",
    "        D_norm = np.array([np.linalg.norm(D[i]) for i in range(len(D))])\n",
    "        x_norm = np.linalg.norm(x)\n",
    "        #Divide the dot product of x and each instance in D by the product of the two norms\n",
    "        #np.dot gives the dot product of two vectors divided by a comma\n",
    "        #D = the docxterm matrix\n",
    "        #x = instance we want to categorize\n",
    "        sims = np.dot(D,x)/(D_norm * x_norm)\n",
    "        #distance measure will be the inverse of cosine similarity\n",
    "        dists = 1 - sims\n",
    "        #We want to return a sorted version of our distances\n",
    "    idx = np.argsort(dists)\n",
    "    \n",
    "    return idx[:K], trainlabelarray[idx[:K]], dists\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   190  191  192  193  \\\n",
       "0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "3  1.0  1.0  1.0  1.0  1.0  1.0  2.0  1.0  1.0  1.0 ...   1.0  2.0  1.0  1.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  2.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "\n",
       "   194  195  196  197  198  199  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import test matrix to run KNN function on\n",
    "testmatrix = pd.read_csv(\"testMatrixModified.txt\",delimiter=\"\\t\", header=None)\n",
    "testmatrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5500, 200)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testmatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 5500)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testmatrix_Tr = testmatrix.T\n",
    "testmatrix_Tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array(testmatrix_Tr.iloc[0])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[685 628 667 152 427]\n"
     ]
    }
   ],
   "source": [
    "x, y, dist = knn_search(t, trainmatrix_Tr2, 5, 1)\n",
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "print y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.92709494,  0.79673989,  0.9320382 ,  0.89790716,  0.94654139,\n",
       "        0.75100253,  0.87022016,  0.83936495,  0.8663802 ,  0.83658124,\n",
       "        0.85889206,  0.91046232,  0.967053  ,  0.8674656 ,  0.85682474,\n",
       "        0.84202209,  0.9559169 ,  0.95930309,  0.81201636,  0.97654623,\n",
       "        0.9759507 ,  0.82749758,  0.93546895,  0.94852203,  0.89320834,\n",
       "        0.9601543 ,  0.97054574,  0.9028059 ,  0.86947952,  0.92402623,\n",
       "        0.86401406,  0.9456762 ,  0.82902992,  0.76739778,  0.86165711,\n",
       "        0.96686511,  0.86091087,  0.9020568 ,  0.9759507 ,  0.95663844,\n",
       "        0.97550939,  0.92957962,  0.88366959,  0.95588511,  0.98953954,\n",
       "        0.95998862,  0.93637152,  0.89704406,  0.95616007,  0.9879854 ,\n",
       "        0.9022188 ,  0.93387535,  0.84695651,  0.93428479,  0.97550939,\n",
       "        0.92957618,  0.92167876,  0.81023414,  0.9721565 ,  0.92547176,\n",
       "        0.96103567,  0.90908324,  0.94943321,  0.84305278,  0.93303296,\n",
       "        0.87675215,  0.87719859,  0.93699842,  0.83269659,  0.92941054,\n",
       "        0.99204644,  0.94604316,  0.93386442,  0.88537336,  0.91715181,\n",
       "        0.8866087 ,  0.95714143,  0.82100941,  0.87927345,  0.9552074 ,\n",
       "        0.9611962 ,  0.98981129,  0.8936604 ,  0.99198357,  0.81932434,\n",
       "        0.93692886,  0.91198579,  0.96313849,  0.95791372,  0.79272359,\n",
       "        0.91124008,  0.92785209,  0.93255395,  0.91221589,  0.96943387,\n",
       "        0.84563216,  0.82991304,  0.9630167 ,  0.98031167,  0.83385556,\n",
       "        0.82956488,  0.88383083,  0.95758102,  0.97036883,  0.94105642,\n",
       "        0.93207724,  0.979464  ,  0.96276425,  0.84874128,  0.78642557,\n",
       "        0.89143389,  0.97131407,  0.96019764,  0.7135654 ,  0.96873067,\n",
       "        0.79396219,  0.75127513,  0.98937885,  0.77451681,  0.95190139,\n",
       "        0.94517513,  0.96019764,  0.99449305,  0.92848777,  0.94496627,\n",
       "        0.94461852,  0.84081102,  0.98603173,  0.9640063 ,  0.90887906,\n",
       "        0.87631548,  0.854058  ,  0.92270751,  0.88235091,  0.87461   ,\n",
       "        0.8349688 ,  0.96818576,  0.86921291,  0.77915273,  0.88489176,\n",
       "        0.98436534,  0.94475501,  0.91691029,  0.98218046,  0.79662346,\n",
       "        0.84478277,  0.94150658,  0.80062667,  0.92944672,  0.9881813 ,\n",
       "        0.92167876,  0.95758102,  0.65693825,  0.96993837,  0.98235264,\n",
       "        0.87793764,  0.96536504,  0.97402378,  0.9700974 ,  0.96773447,\n",
       "        0.8577224 ,  0.8558015 ,  0.91420338,  0.93575512,  0.86924429,\n",
       "        0.91428286,  0.96784909,  0.85454516,  0.94956846,  0.87071402,\n",
       "        0.94248205,  0.98041557,  0.95975782,  0.98409288,  0.77251054,\n",
       "        0.93653322,  0.85478853,  0.92576678,  0.85823406,  0.86208059,\n",
       "        0.95428795,  0.92867903,  0.79974953,  0.93620858,  0.98071766,\n",
       "        0.88829275,  0.90588072,  0.94996679,  0.98939525,  0.94641516,\n",
       "        0.9546007 ,  0.89283031,  0.95111925,  0.8571381 ,  0.68850104,\n",
       "        0.92113242,  0.9400105 ,  0.91582744,  0.94375984,  0.94638022,\n",
       "        0.84489279,  0.81729542,  0.72898652,  0.78066338,  0.76750148,\n",
       "        0.95428795,  0.97509253,  0.95160171,  0.83678246,  0.9702114 ,\n",
       "        0.95939581,  0.98009882,  0.95207573,  0.98409288,  0.94419413,\n",
       "        0.83636806,  0.96351827,  0.93138765,  0.99071883,  0.78334338,\n",
       "        0.93015867,  0.89267399,  0.94285994,  0.84626331,  0.90380279,\n",
       "        0.8245884 ,  0.97613932,  0.96465085,  0.97714398,  0.96654506,\n",
       "        0.88645908,  0.73225097,  0.8204442 ,  0.95635123,  0.9028059 ,\n",
       "        0.85852247,  0.87081772,  0.96129933,  0.81747862,  0.95008572,\n",
       "        0.95008572,  0.96686511,  0.94091641,  0.92652816,  0.9602322 ,\n",
       "        0.95858139,  0.8071766 ,  0.91056611,  0.92067833,  0.93402034,\n",
       "        0.87869788,  0.92283914,  0.78087726,  0.76395452,  0.75961243,\n",
       "        0.94517513,  0.97686237,  0.82871555,  0.97300472,  0.75998272,\n",
       "        0.94836532,  0.97291792,  0.88251814,  0.86502362,  0.84304895,\n",
       "        0.87142429,  0.82184027,  0.78686914,  0.91182336,  0.91906474,\n",
       "        0.94831062,  0.98860068,  0.95731672,  0.9292881 ,  0.94358746,\n",
       "        0.93676069,  0.93400988,  0.89261856,  0.96628881,  0.94822338,\n",
       "        0.85456348,  0.9743541 ,  0.9801258 ,  0.85683593,  0.84517147,\n",
       "        0.91056611,  0.95677296,  0.95690536,  0.96824772,  0.93143193,\n",
       "        0.83377844,  0.8198271 ,  0.93098523,  0.89630827,  0.9459874 ,\n",
       "        0.94082672,  0.96733085,  0.86308582,  0.78874866,  0.9009306 ,\n",
       "        0.95924516,  0.88747183,  0.83790165,  0.84500142,  0.99018191,\n",
       "        0.77912413,  0.97054574,  0.96701017,  0.8744368 ,  0.96644413,\n",
       "        0.93994237,  0.90475387,  0.86489161,  0.89886643,  0.98939525,\n",
       "        0.94657345,  0.82454861,  0.7328109 ,  0.84487409,  0.82510205,\n",
       "        0.92183976,  0.85917673,  0.8731737 ,  0.9553171 ,  0.94517513,\n",
       "        0.90211004,  0.95370348,  0.96103567,  0.92111008,  0.90654401,\n",
       "        0.84762988,  0.91751443,  0.91516203,  0.99545253,  0.84365091,\n",
       "        0.94743562,  0.85120012,  0.96276425,  0.98329034,  0.92819042,\n",
       "        0.92965607,  0.94142524,  0.98299457,  0.81449271,  0.89165715,\n",
       "        0.87986   ,  0.78324112,  0.91809795,  0.84389517,  0.88979225,\n",
       "        0.9461842 ,  0.89852766,  0.98299457,  0.93586852,  0.84833157,\n",
       "        0.92622267,  0.74158709,  0.8879565 ,  0.78215953,  0.91408375,\n",
       "        0.93471856,  0.93770897,  0.89289731,  0.94777485,  0.81562201,\n",
       "        0.95693924,  0.91182891,  0.93579828,  0.96250656,  0.97793085,\n",
       "        0.96658069,  0.87503615,  0.75457588,  0.91995908,  0.93597508,\n",
       "        0.89123293,  0.95111107,  0.89544774,  0.94804757,  0.99109023,\n",
       "        0.96913566,  0.91038529,  0.90823371,  0.96818576,  0.97216254,\n",
       "        0.9427299 ,  0.88592414,  0.87774843,  0.93994237,  0.90547591,\n",
       "        0.79113174,  0.78149892,  0.95875441,  0.92907074,  0.93838447,\n",
       "        0.9204644 ,  0.92480271,  0.90808591,  0.97879051,  0.96793426,\n",
       "        0.94905645,  0.9889237 ,  0.97953493,  0.89836994,  0.85917673,\n",
       "        0.94173593,  0.96374431,  0.96316246,  0.9320382 ,  0.82729414,\n",
       "        0.883359  ,  0.91010068,  0.88069661,  0.88310702,  0.87358304,\n",
       "        0.98665985,  0.70479772,  0.91339596,  0.79236323,  0.72002498,\n",
       "        0.96103567,  0.91428286,  0.9258492 ,  0.97185548,  0.98611513,\n",
       "        0.94509226,  0.86936914,  0.67243379,  0.73716182,  0.92304223,\n",
       "        0.89760686,  0.96536504,  0.88059291,  0.85343751,  0.77498919,\n",
       "        0.95370348,  0.97525022,  0.85761705,  0.91990625,  0.97352895,\n",
       "        0.91298635,  0.87773903,  0.94371096,  0.84990036,  0.96818576,\n",
       "        0.95784046,  0.80604837,  0.90816021,  0.72309453,  0.89974206,\n",
       "        0.94308896,  0.97142997,  0.88775264,  0.86963653,  0.927029  ,\n",
       "        0.89225806,  0.93987674,  0.77634602,  0.98434892,  0.99140812,\n",
       "        0.9801258 ,  0.95882282,  0.93618243,  0.87264112,  0.93637152,\n",
       "        0.80050256,  0.9467646 ,  0.95428795,  0.95124398,  0.9319783 ,\n",
       "        0.98292669,  0.87802237,  0.78021733,  0.83238082,  0.78442014,\n",
       "        0.84154293,  0.92713288,  0.81323785,  0.8137149 ,  0.90712782,\n",
       "        0.99353951,  0.97033307,  0.95834538,  0.85570418,  0.85612821,\n",
       "        0.98603173,  0.92347558,  0.8705497 ,  0.98061852,  0.93217182,\n",
       "        0.93938883,  0.92570963,  0.9096395 ,  0.93241713,  0.96392604,\n",
       "        0.95500787,  0.96786525,  0.92883542,  0.89848407,  0.93215801,\n",
       "        0.86570705,  0.83692999,  0.8577224 ,  0.92167876,  0.89493755,\n",
       "        0.91644319,  0.96201238,  0.97263742,  0.91176318,  0.92077146,\n",
       "        0.79850983,  0.90812945,  0.9072292 ,  0.94558581,  0.85453127,\n",
       "        0.88783458,  0.97555554,  0.98924482,  0.97071262,  0.93819856,\n",
       "        0.95665714,  0.95565671,  0.84079055,  0.90479983,  0.94155351,\n",
       "        0.92125361,  0.79031424,  0.9102808 ,  0.90449636,  0.90407128,\n",
       "        0.9416739 ,  0.90789818,  0.79290088,  0.82717877,  0.94048101,\n",
       "        0.96627698,  0.86048534,  0.92000392,  0.77206361,  0.91751443,\n",
       "        0.86356623,  0.77292701,  0.87274305,  0.91001575,  0.93366273,\n",
       "        0.99584048,  0.90770808,  0.83568415,  0.84022185,  0.83158201,\n",
       "        0.96201238,  0.93428479,  0.88356098,  0.96549261,  0.95731672,\n",
       "        0.98979674,  0.93098686,  0.89183159,  0.9029395 ,  0.97402378,\n",
       "        0.9915722 ,  0.9640063 ,  0.97244806,  0.94821988,  0.87011892,\n",
       "        0.92340032,  0.82318695,  0.94820059,  0.78864685,  0.80470874,\n",
       "        0.83802834,  0.83313611,  0.8601744 ,  0.96677111,  0.95081387,\n",
       "        0.94344135,  0.8726891 ,  0.85167655,  0.9329297 ,  0.96903429,\n",
       "        0.88249341,  0.84829964,  0.93637152,  0.96247397,  0.94343423,\n",
       "        0.91871842,  0.87020129,  0.97888415,  0.89994885,  0.89837314,\n",
       "        0.85445122,  0.91092013,  0.84905283,  0.91014856,  0.90559756,\n",
       "        0.94693018,  0.89795578,  0.97784741,  0.92971029,  0.90042041,\n",
       "        0.9759507 ,  0.91318645,  0.72730653,  0.92133961,  0.93665245,\n",
       "        0.92494794,  0.99185321,  0.77153404,  0.96182291,  0.97402378,\n",
       "        0.9514661 ,  0.93094008,  0.98167969,  0.92126378,  0.88473664,\n",
       "        0.90455729,  0.77845916,  0.97154448,  0.944313  ,  0.97154448,\n",
       "        0.91935418,  0.90214934,  0.96190663,  0.95748644,  0.93793512,\n",
       "        0.91222305,  0.86491804,  0.97527942,  0.57680202,  0.81019776,\n",
       "        0.83553569,  0.79965293,  0.80930071,  0.97020324,  0.93539507,\n",
       "        0.92841237,  0.9354697 ,  0.91565011,  0.99216788,  0.88235091,\n",
       "        0.9911092 ,  0.90562372,  0.96810429,  0.76876019,  0.92701313,\n",
       "        0.93432945,  0.86269714,  0.85159009,  0.93360379,  0.83916414,\n",
       "        0.76309448,  0.95119919,  0.95347025,  0.85285351,  0.9201469 ,\n",
       "        0.94879945,  0.97879051,  0.81927901,  0.98577224,  0.88946473,\n",
       "        0.91686627,  0.95197135,  0.98369156,  0.95522596,  0.88002099,\n",
       "        0.89096801,  0.79773286,  0.65436091,  0.93885382,  0.94329858,\n",
       "        0.94860215,  0.7481351 ,  0.89268752,  0.9412467 ,  0.92785209,\n",
       "        0.85692532,  0.93431182,  0.9872743 ,  0.88707066,  0.77847408,\n",
       "        0.92827525,  0.77261597,  0.97784741,  0.97402378,  0.98939525,\n",
       "        0.45645871,  0.91025859,  0.87578549,  0.92045714,  0.85505566,\n",
       "        0.94852203,  0.91755005,  0.88241119,  0.8981129 ,  0.9012254 ,\n",
       "        0.93701102,  0.95871239,  0.81963022,  0.97094825,  0.86829491,\n",
       "        0.98163204,  0.96326408,  0.92607039,  0.77538572,  0.94194403,\n",
       "        0.84375159,  0.91785599,  0.98986885,  0.9805935 ,  0.95693924,\n",
       "        0.70633011,  0.97750394,  0.91420338,  0.99336627,  0.83802316,\n",
       "        0.75903817,  0.91718227,  0.9776346 ,  0.83942889,  0.82692535,\n",
       "        0.9759507 ,  0.77596323,  0.96424388,  0.97965516,  0.913289  ,\n",
       "        0.97271325,  0.98577224,  0.93485835,  0.90270533,  0.97702009,\n",
       "        0.93285352,  0.75940949,  0.76009748,  0.95528614,  0.89092261,\n",
       "        0.86804069,  0.9400105 ,  0.97810394,  0.875364  ,  0.98540263,\n",
       "        0.83867237,  0.92045752,  0.85756081,  0.89501837,  0.97212386,\n",
       "        0.82333752,  0.94378728,  0.89844591,  0.95635123,  0.86897501,\n",
       "        0.93428479,  0.98235264,  0.95335927,  0.93373022,  0.87574417,\n",
       "        0.98163204,  0.83675743,  0.96818576,  0.87164651,  0.93136786,\n",
       "        0.93265082,  0.95976694,  0.94244588,  0.76489013,  0.98192713,\n",
       "        0.81452319,  0.94244588,  0.97606347,  0.79765133,  0.94638022,\n",
       "        0.84094064,  0.97261866,  0.92283914,  0.905836  ,  0.8361981 ,\n",
       "        0.9200079 ,  0.82835032,  0.86764477,  0.93587891,  0.90481057,\n",
       "        0.98658594,  0.87574417,  0.94909722,  0.89138723,  0.93977836,\n",
       "        0.88218296,  0.90549763,  0.84029379,  0.8032065 ,  0.91582744,\n",
       "        0.962383  ,  0.97817561,  0.76540287,  0.98953954,  0.83484957,\n",
       "        0.94546131,  0.90042041,  0.72719516,  0.95500787,  0.85030212])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[685 628 667 152 427]\n",
      "\n",
      "\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "print x\n",
    "print '\\n'\n",
    "print trainlabelarray[x]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.92709494]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]\n",
      " [ 0.79673989]]\n"
     ]
    }
   ],
   "source": [
    "print dist[trainlabelarray]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1\n",
       "685  1\n",
       "628  1\n",
       "667  1\n",
       "152  1\n",
       "427  1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlabel = trainlabels_ix.iloc[x]\n",
    "nlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlabel.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Create a function to compute the classification accuracy over the test data set (ratio of correct predictions to the number of test instances). This function will call the classifier function on all the test instances and in each case compares the actual test class label to the predicted class label.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print Counter(nlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[685 628 703 266 510]\n"
     ]
    }
   ],
   "source": [
    "x_Euc, y_Euc, dist = knn_search(t, trainmatrix_Tr2, 5, 0)\n",
    "print x_Euc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "print y_Euc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  30.28200786   17.3781472    17.32050808   16.4924225    16.91153453\n",
      "   26.45751311   20.39607805   16.85229955   17.4642492    22.93468988\n",
      "   18.97366596   20.22374842   46.62617291   20.78460969   16.91153453\n",
      "   18.24828759   17.60681686   17.97220076   19.72308292   20.51828453\n",
      "   16.46207763   20.0748599    16.43167673   17.02938637   18.68154169\n",
      "   21.9544984    16.82260384   17.40689519   16.97056275   54.69917732\n",
      "   18.52025918   19.77371993   16.09347694   24.63736999   18.38477631\n",
      "   17.2626765    19.10497317   26.34387974   15.87450787  219.98863607\n",
      "   16.43167673   20.59126028   17.80449381   30.98386677   16.79285562\n",
      "   23.04343724   16.79285562   16.673332     24.0208243    45.01110974\n",
      "   20.61552813   17.43559577   18.97366596   15.93737745   16.43167673\n",
      "   16.52271164   27.94637722   18.43908891   16.97056275   19.5192213\n",
      "   16.2788206    23.97915762   17.08800749   19.20937271   18.78829423\n",
      "   18.22086716   21.04756518   18.13835715   19.72308292   15.87450787\n",
      "   17.57839583   17.88854382   18.35755975   19.07878403   19.13112647\n",
      "   17.43559577   18.46618531   28.12472222   16.21727474   42.10700654\n",
      "   27.31300057   16.85229955   29.69848481   17.54992877   17.60681686\n",
      "   19.8242276    23.9582971    19.46792233   18.57417562   21.16601049\n",
      "   17.23368794   17.08800749   17.77638883   24.           19.77371993\n",
      "   26.17250466   22.56102835   17.63519209   18.30300522   17.8605711\n",
      "   19.74841766   16.03121954   16.58312395   20.02498439   34.19064199\n",
      "   16.61324773   21.84032967   17.60681686   17.94435844   15.96871942\n",
      "   18.24828759   18.97366596   16.24807681   17.23368794   22.27105745\n",
      "   27.16615541   21.74856317   23.74868417   26.68332813   15.8113883\n",
      "   17.29161647   16.24807681   27.87471973   18.35755975   21.9317122\n",
      "   16.43167673   15.74801575   18.05547009   17.           16.85229955\n",
      "   18.46618531   17.17556404   17.52141547   18.           17.60681686\n",
      "   26.66458325   16.64331698   18.84144368   16.37070554   16.34013464\n",
      "   22.44994432   17.2626765    20.02498439   17.1464282    17.52141547\n",
      "   19.07878403   67.29041537   20.88061302   20.           45.67274899\n",
      "   17.11724277   16.58312395   19.77371993   18.68154169   17.17556404\n",
      "   23.34523506   21.14237451   17.17556404   19.94993734   16.61324773\n",
      "   16.94107435   17.43559577   16.79285562   27.64054992   18.57417562\n",
      "   16.1245155    19.39071943   16.52271164   17.63519209   16.82260384\n",
      "   57.68882041   18.33030278   31.95309062   17.52141547   25.11971337\n",
      "   20.39607805   17.80449381   16.40121947   23.43074903   24.24871131\n",
      "   16.43167673   16.4924225    20.39607805   20.34698995   18.41195264\n",
      "   17.02938637   18.22086716   18.97366596   16.76305461   19.18332609\n",
      "   24.57641145   18.65475811   17.20465053   20.49390153   18.33030278\n",
      "   18.1934054    17.40689519   16.15549442   18.84144368   17.3781472\n",
      "   20.34698995   17.05872211   43.53159772   17.23368794   17.43559577\n",
      "   16.43167673   45.81484476   19.20937271   21.02379604   17.66352173\n",
      "   25.21904043   18.24828759   39.66106403   17.52141547   18.89444363\n",
      "   19.49358869   74.35724578   17.69180601   17.08800749   17.4642492\n",
      "   17.60681686   18.97366596   16.37070554   19.92485885   15.68438714\n",
      "   19.           17.4642492    17.8325545    16.55294536   22.84731932\n",
      "   18.84144368   31.09662361   18.97366596   16.52271164   15.93737745\n",
      "   17.54992877   18.94729532   20.09975124   16.40121947   18.30300522\n",
      "   16.2788206    17.2626765    31.28897569   16.70329309   17.34935157\n",
      "   17.20465053   16.88194302   16.43167673   38.20994635   17.88854382\n",
      "   19.5192213    17.17556404   19.26136028   20.59126028   25.61249695\n",
      "   17.29161647   18.97366596   16.55294536   17.05872211   19.49358869\n",
      "   18.76166304   19.36491673   16.82260384   18.84144368   19.6977156\n",
      "   16.34013464   15.62049935   19.59591794   17.57839583   17.66352173\n",
      "   22.71563338   47.16990566   17.74823935   21.14237451   20.88061302\n",
      "   17.63519209   24.79919354   17.20465053   17.20465053   17.52141547\n",
      "   19.46792233   40.02499219   16.85229955   18.35755975   15.96871942\n",
      "   16.43167673   17.69180601   21.09502311   35.25620513   16.30950643\n",
      "   28.72281323   16.1245155    17.66352173   18.24828759   17.34935157\n",
      "   17.4642492    26.15339366   18.46618531   17.3781472    19.28730152\n",
      "   16.673332     18.60107524   22.49444376   37.84177586   16.94107435\n",
      "   25.3179778    16.82260384   18.16590212   26.01922366   32.03123476\n",
      "   16.97056275   16.70329309   25.72936066   16.73320053   16.76305461\n",
      "   22.29349681   16.21727474   19.46792233   17.02938637   18.22086716\n",
      "   18.24828759   16.4924225    17.77638883   17.54992877   17.29161647\n",
      "   19.39071943   16.0623784    21.09502311   20.02498439   21.58703314\n",
      "   20.02498439   17.23368794   16.34013464   44.754888     25.25866188\n",
      "   20.83266666   22.64950331   17.60681686   17.34935157   17.88854382\n",
      "   18.           18.57417562   16.09347694   15.71623365   24.93992783\n",
      "   23.60084744   19.39071943   17.97220076   22.8035085    16.           24.8394847\n",
      "   20.22374842   17.29161647   17.1464282    17.52141547   17.74823935\n",
      "   20.76053949   26.13426869   20.4450483    24.91987159   17.94435844\n",
      "   28.28427125   24.22808288   18.05547009   20.174241     24.2899156\n",
      "   19.92485885   20.92844954   17.57839583   19.28730152   17.23368794\n",
      "   15.8113883    28.54820485   17.72004515   17.57839583   17.1464282\n",
      "   17.77638883   16.09347694   17.           17.20465053   17.52141547\n",
      "   21.14237451   22.8035085    17.40689519   22.11334439   17.60681686\n",
      "   16.94107435   21.81742423   16.97056275   16.1245155    18.92088793\n",
      "   18.94729532   76.5702292    18.89444363   22.09072203   17.05872211\n",
      "   18.49324201   19.54482029   15.93737745   17.3781472    16.61324773\n",
      "   16.673332     18.11077028   18.38477631   16.4924225    56.98245344\n",
      "   17.72004515   24.20743687   17.32050808   16.0623784    17.29161647\n",
      "   21.58703314   16.76305461   17.52141547   20.37154879   18.27566688\n",
      "   26.           19.20937271   26.2297541    16.43167673   18.1934054\n",
      "   21.16601049   30.61045573   16.94107435   16.30950643  293.89794147\n",
      "   20.32240143   22.71563338   18.24828759   19.74841766   29.58039892\n",
      "   21.14237451   15.87450787   19.39071943   20.           17.40689519\n",
      "   25.57342371   18.16590212   18.94729532   17.11724277   17.32050808\n",
      "   34.58323293   16.76305461   18.           16.64331698   17.80449381\n",
      "   18.97366596   16.58312395   18.57417562   20.76053949   16.73320053\n",
      "   19.           18.02775638   17.17556404   17.80449381   18.           16.2788206\n",
      "   24.59674775   28.80972058   61.16371473   16.85229955   18.70828693\n",
      "   19.72308292   18.78829423   15.96871942   18.33030278   17.40689519\n",
      "   16.43167673   18.43908891   18.68154169   19.13112647   18.02775638\n",
      "   19.05255888   16.79285562   24.91987159   24.06241883   22.627417\n",
      "   16.79285562   17.08800749   17.63519209   18.49324201   18.76166304\n",
      "   16.18641406   16.55294536   19.84943324   18.05547009   16.88194302\n",
      "   18.65475811   18.38477631   20.37154879   16.94107435   20.61552813\n",
      "   19.6977156    27.40437921   21.9317122    16.46207763   47.69696007\n",
      "   81.76184929   17.20465053  128.38613632   17.43559577   16.03121954\n",
      "   20.54263858   17.11724277   17.8605711    17.8605711    18.33030278\n",
      "   25.82634314   18.27566688   18.16590212   15.65247584   34.20526275\n",
      "   22.64950331   17.32050808   21.44761059   17.49285568   23.76972865\n",
      "   16.73320053   18.84144368   18.24828759   53.07541804   33.36165464\n",
      "   19.54482029   20.04993766   18.02775638   17.43559577   31.63858404\n",
      "   17.49285568   17.49285568   23.64318084   19.20937271   20.83266666\n",
      "   27.54995463   17.40689519   17.           18.05547009   18.08314132\n",
      "   16.24807681   21.9089023    17.23368794   17.1464282    17.77638883\n",
      "   17.08800749   17.80449381   17.8605711    21.88606863   19.10497317\n",
      "   33.37663854   20.           18.54723699   18.33030278   15.93737745\n",
      "   16.30950643   17.94435844   16.15549442   24.31049156   57.34108475\n",
      "   17.69180601   16.64331698   16.34013464   17.3781472    17.           17.\n",
      "   19.4422221    15.84297952   17.20465053   18.92088793   21.81742423\n",
      "   27.54995463   22.8035085    16.15549442   17.29161647   19.59591794\n",
      "   16.55294536   17.74823935   17.66352173   91.79324594   17.4642492\n",
      "   17.80449381   16.70329309   17.49285568   16.37070554   17.17556404\n",
      "   16.88194302   17.17556404   24.08318916   22.75961335   21.54065923\n",
      "   17.54992877   21.02379604   18.94729532   17.8605711    17.\n",
      "   23.10844002   19.31320792   17.97220076   20.97617696   16.61324773\n",
      "   18.46618531   17.02938637   17.43559577   17.02938637   17.97220076\n",
      "   16.79285562   21.07130751   16.64331698   17.49285568   22.27105745\n",
      "   16.30950643   16.34013464   18.46618531   20.19900988   20.78460969\n",
      "   18.62793601   20.02498439   15.84297952   23.68543856   16.91153453\n",
      "   16.79285562   19.02629759   21.3541565    18.65475811   36.37306696\n",
      "   17.11724277   20.61552813   29.25747768   22.84731932   18.57417562\n",
      "   15.32970972   17.11724277   18.54723699   29.73213749   17.23368794\n",
      "   18.734994     18.           17.49285568   36.98648402   30.85449724\n",
      "   17.63519209   18.          586.91737067   16.73320053   20.68816087\n",
      "   21.86321111   16.           16.70329309   21.61018278   18.08314132\n",
      "   16.673332     21.49418526   31.1608729    19.92485885   20.34698995\n",
      "   22.82542442   22.02271555   21.9544984    16.70329309   18.70828693\n",
      "   16.2788206    16.64331698   17.88854382   17.8605711    19.4422221\n",
      "   27.05549852   16.94107435   21.40093456   19.46792233   22.24859546\n",
      "   20.09975124   24.87971061   21.9089023    17.63519209   17.4642492    18.\n",
      "   18.30300522   19.10497317   17.4642492    16.43167673   18.57417562\n",
      "   17.29161647   18.81488772   20.59126028   16.61324773   16.34013464\n",
      "   16.76305461   13.34166406  212.58174898   18.16590212   32.38826948\n",
      "   17.60681686   17.02938637   18.734994     19.49358869   16.30950643\n",
      "   19.6977156    16.82260384   19.57038579   17.29161647   23.19482701\n",
      "   20.54263858   17.05872211   16.94107435   17.           15.39480432\n",
      "   20.59126028   26.90724809   15.87450787   24.41311123   16.91153453\n",
      "   24.2899156    17.20465053   15.90597372   16.79285562   18.35755975\n",
      "   31.06444913   16.91153453   23.21637353   27.36786437   16.70329309\n",
      "   30.85449724   18.734994     19.5192213    18.68154169   29.27456234\n",
      "   17.66352173   18.05547009   16.2788206    20.14944168   20.24845673\n",
      "   17.60681686   16.64331698   21.02379604   23.57965225   43.49712634\n",
      "   19.87460691   17.32050808   17.40689519   17.80449381   24.16609195\n",
      "   16.24807681   21.72556098   20.97617696   17.11724277   15.84297952\n",
      "   27.34958866   24.37211521   17.69180601   19.8242276    16.52271164\n",
      "   17.57839583   18.92088793   16.0623784    17.3781472    21.23676058\n",
      "   16.61324773   17.05872211   16.4924225    15.77973384   18.1934054\n",
      "   18.13835715   18.24828759   36.16628264   16.70329309   16.0623784\n",
      "   35.11409973   18.65475811   16.70329309   32.86335345   33.85262176\n",
      "   17.3781472    20.83266666   19.28730152   17.17556404   21.49418526\n",
      "   17.40689519   20.39607805   19.4422221    16.40121947   20.29778313\n",
      "  169.67910891   18.24828759   16.61324773   18.1934054    16.70329309\n",
      "   24.73863375   16.2788206    17.8605711    21.04756518   20.\n",
      "   16.15549442   25.19920634   16.64331698   26.62705391   16.79285562\n",
      "   18.30300522   16.85229955   17.02938637   16.82260384   15.71623365\n",
      "   19.18332609]\n"
     ]
    }
   ],
   "source": [
    "print dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500\n"
     ]
    }
   ],
   "source": [
    "testvecs = len(t)\n",
    "print testvecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify0(inX, dataSet, labels, k):\n",
    "    dataSetSize = dataSet.shape[0]\n",
    "    diffMat = tile(inX, (dataSetSize,1)) - dataSet\n",
    "    sqDiffMat = diffMat**2\n",
    "    sqDistances = sqDiffMat.sum(axis=1)\n",
    "    distances = sqDistances**0.5\n",
    "    sortedDistIndicies = distances.argsort()     \n",
    "    classCount={}          \n",
    "    for i in range(k):\n",
    "        voteIlabel = labels[sortedDistIndicies[i]]\n",
    "        classCount[voteIlabel] = classCount.get(voteIlabel,0) + 1\n",
    "    sortedClassCount = sorted(classCount.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedClassCount[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-c665fcf06f4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#give knn.classify0 the first row of the vs_test_norm data, the training data, vs_target_train which are the labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#and k = 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mclassifierResult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassify0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestmatrix_Tr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainmatrix_Tr2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainlabelarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"the classifier came back with: %s, the real answer is: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mclassifierResult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainlabelarray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mclassifierResult\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtrainlabelarray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0merrorCount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\James Cooper\\Anaconda_9-17\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2060\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2061\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2062\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2063\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2064\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\James Cooper\\Anaconda_9-17\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2067\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2068\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2069\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2071\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\James Cooper\\Anaconda_9-17\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1530\u001b[0m         \u001b[1;34m\"\"\"Return the cached item, item represents a label indexer.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1531\u001b[0m         \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_item_cache\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1532\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1533\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1534\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type"
     ]
    }
   ],
   "source": [
    "errorCount = 0.0\n",
    "for i in range(testvecs):\n",
    "    #give knn.classify0 the first row of the vs_test_norm data, the training data, vs_target_train which are the labels\n",
    "    #and k = 3\n",
    "    classifierResult = classify0(testmatrix_Tr[i,:], trainmatrix_Tr2, trainlabelarray, 5)\n",
    "    print \"the classifier came back with: %s, the real answer is: %s\" % (classifierResult, trainlabelarray[i])\n",
    "    if (classifierResult != trainlabelarray[i]): errorCount += 1.0\n",
    "\n",
    "#divide the count of errors by the total number of test cases\n",
    "print \"the total error rate is: %f\" %(errorCount/float(numtestvecs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Run your accuracy function on a range of values for K in order to compare accuracy values for different numbers of neighbors. Do this both using Euclidean Distance as well as Cosine similarity measure. [For example, you can try evaluating your classifiers on a range of values of K from 1 through 20 and present the results as a table or a graph].*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = pd.read_csv(\"trainMatrixModified.txt\",delimiter=\"\\t\", header=None)\n",
    "trainlabs = pd.read_csv(\"trainClasses.txt\",delimiter=\"\\t\", header=None)\n",
    "test = pd.read_csv(\"testMatrixModified.txt\",delimiter=\"\\t\", header=None)\n",
    "testlabs = pd.read_csv(\"testClasses.txt\", delimiter=\"\\t\", header=None)\n",
    "\n",
    "def Kaccuracy(training, trainlabs, test, testlabs, k, measure):\n",
    "    correct = 0\n",
    "    for i in range(test.shape[0]):\n",
    "        predict = knn_search(test[i], training, k, measure)\n",
    "        if predict[0] == testlabs[i,:][1]:\n",
    "            correct += 1\n",
    "    \n",
    "    accuracy_rate = float(correct)/float(test.shape[0])\n",
    "    return accuracy_rate\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "800L",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-aee6cde30a09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mKaccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainlabs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestlabs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-45-31428dbeb78d>\u001b[0m in \u001b[0;36mKaccuracy\u001b[1;34m(training, trainlabs, test, testlabs, k, measure)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeasure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtestlabs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mcorrect\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-e5ba04d4e91f>\u001b[0m in \u001b[0;36mknn_search\u001b[1;34m(x, D, K, measure)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m#Cosine similarity is the dot product divided by the multiple of the norms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m#D_norm = normalized vectors of D (all rows)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mD_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mx_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m#Divide the dot product of x and each instance in D by the product of the two norms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\James Cooper\\Anaconda_9-17\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2060\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2061\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2062\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2063\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2064\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\James Cooper\\Anaconda_9-17\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2067\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2068\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2069\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2071\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\James Cooper\\Anaconda_9-17\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1532\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1533\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1534\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1535\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\James Cooper\\Anaconda_9-17\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3589\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3590\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3591\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\James Cooper\\Anaconda_9-17\\lib\\site-packages\\pandas\\core\\indexes\\base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2393\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2394\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2395\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2397\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5239)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5085)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item (pandas\\_libs\\hashtable.c:13913)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item (pandas\\_libs\\hashtable.c:13857)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 800L"
     ]
    }
   ],
   "source": [
    "Kaccuracy(training, trainlabs, test, testlabs, 5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Using Python, modify the training and test data sets so that term weights are converted to TFxIDF weights (instead of raw term frequencies). [See class notes on Text Categorization]. Then, rerun your evaluation on the range of K values (as above) and compare the results to the results without using TFxIDF weights.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF = np.array([(trainmatrix!=0).sum(1)]).T\n",
    "print DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ndocs = trainmatrix.shape[1]\n",
    "Matrix_1s = np.ones(np.shape(trainmatrix), dtype=float)*Ndocs\n",
    "Matrix_1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IDF = np.log2(np.divide(Matrix_1s, DF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TD_IDF = trainmatrix * IDF\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "TD_IDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn_search(x, D, K, measure):\n",
    "    \n",
    "    if measure == 0:\n",
    "        #euclidean distance from other points - subtract x from each row in D, take the sum of the squares, and use the \n",
    "        #square root - axis = 1 here because we are adding up all the terms\n",
    "        dists = np.sqrt(((D - x)**2).sum(axis=1))\n",
    "        \n",
    "    elif measure == 1:\n",
    "        #find vector norm in each instance in D as well as the vecotr norm of x\n",
    "        #Cosine similarity is the dot product divided by the multiple of the norms\n",
    "        #D_norm = normalized vectors of D (all rows)\n",
    "        D_norm = np.array([np.linalg.norm(D[i]) for i in range(len(D))])\n",
    "        x_norm = np.linalg.norm(x)\n",
    "        #Divide the dot product of x and each instance in D by the product of the two norms\n",
    "        #np.dot gives the dot product of two vectors divided by a comma\n",
    "        #D = the docxterm matrix\n",
    "        #x = instance we want to categorize\n",
    "        sims = np.dot(D,x)/(D_norm * x_norm)\n",
    "        #distance measure will be the inverse of cosine similarity\n",
    "        dists = 1 - sims\n",
    "        #We want to return a sorted version of our distances\n",
    "    idx = np.argsort(dists)\n",
    "    \n",
    "    return idx[:K], trainlabelarray[idx[:K]], dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = np.array(testmatrix_Tr.iloc[45][:])\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_TDIDF = x1 * IDF.T[0]\n",
    "print x_TDIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DT_IDF = TD_IDF.T\n",
    "DT_IDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DT2_IDF = np.array(DT_IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y, dist = knn_search(x_TDIDF, DT_IDF, 5, 1)\n",
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print DT2_IDF[x]\n",
    "print \"\\n\"\n",
    "print \"Distances to x: \", np.sort(y)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### *Load and preprocess the data using Numpy or Pandas and the preprocessing functions from scikit-learn. Specifically, you need to separate the target attribute (\"pep\") from the portion of the data to be used for training and testing. You will need to convert the selected dataset into the Standard Spreadsheet format (scikit-learn functions generally assume that all attributes are in numeric form). Finally, you need to split the transformed data into training and test sets (using 80%-20% randomized split). [Review Ipython Notebook examples from Week 4 for different ways to perform these tasks.]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bankdata = pd.read_csv('bank_data.csv', index_col=0)\n",
    "bankdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a random permutation of the data\n",
    "bankpermutation = bankdata.reindex(np.random.permutation(bankdata.index))\n",
    "bankpermutation.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(bankpermutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Isolate target variable\n",
    "bank_target = bankpermutation.pep\n",
    "bank_target.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bank_names = bankpermutation.columns.values\n",
    "bank_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We need to use dummy variables for categorical attributes\n",
    "bank_dum = pd.get_dummies(bankpermutation[['age', 'income', 'children', 'gender', 'region', 'married', 'car',\n",
    "       'savings_acct', 'current_acct', 'mortgage']])\n",
    "bank_dum.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Next step is to split the data\n",
    "#To be able to evaluate the accuracy of our predictions, we will split the data into \n",
    "#training and test sets. In this case, we will use 80% for training and the remaining 20% for testing. \n",
    "#Note that we must also do the same split to the target attribute.\n",
    "#So vs[:tsize ] = 0 to tsize\n",
    "\n",
    "tpercent = 0.8\n",
    "tsize = int(np.floor(tpercent * len(bank_dum)))\n",
    "bank_dum_train = bank_dum[:tsize]\n",
    "bank_dum_test = bank_dum[tsize:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print bank_dum_train.shape\n",
    "print bank_dum_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We need to do the same for the target attribute\n",
    "bank_target_train1 = bank_target[0:int(tsize)]\n",
    "bank_target_test1 = bank_target[int(tsize):len(bank_target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print bank_target_train1.shape\n",
    "print bank_target_test1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### *Run scikit-learn's KNN classifier on the test set. Note: in the case of KNN, you must first normalize the data so that all attributes are in the same scale (normalize so that the values are between 0 and 1). Generate the confusion matrix (visualize it using Matplotlib), as well as the classification report. Also, computing the average accuracy score. Experiment with different values of K and the weight parameter for KNN to see if you can improve accuracy (you do not need to provide the details of all of your experimentation, but provide a short discussion what parameters worked best).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We create a min max object, we use it by calling the fit function - we are fitting the minmax normalization to the training data\n",
    "min_max_scale = preprocessing.MinMaxScaler()\n",
    "min_max_scale.fit(bank_dum_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#So we apply the normalization to the data\n",
    "#Note that it is possible that the min max  will be different in the test and training, so you may have slightly\n",
    "#different scales\n",
    "bank_train_norm = min_max_scale.fit_transform(bank_dum_train)\n",
    "bank_test_norm = min_max_scale.fit_transform(bank_dum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2, linewidth=100)\n",
    "bank_train_norm[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn6 = KNeighborsClassifier(n_neighbors = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn6.fit(bank_train_norm, bank_target_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_1 = knn6.predict(bank_test_norm)\n",
    "print(\"Test set precitions:\\n {}\".format(pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn6.score(bank_test_norm, bank_target_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn4 = KNeighborsClassifier(n_neighbors = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn4.fit(bank_train_norm, bank_target_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_2 = knn4.predict(bank_test_norm)\n",
    "print(\"Test set precitions:\\n {}\".format(pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn4.score(bank_test_norm, bank_target_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn3 = KNeighborsClassifier(n_neighbors = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn3.fit(bank_train_norm, bank_target_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_3 = knn3.predict(bank_test_norm)\n",
    "print(\"Test set precitions:\\n {}\".format(pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn3.score(bank_test_norm, bank_target_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn = np.arange(1,9)\n",
    "train = np.empty(len(nn))\n",
    "test = np.empty(len(nn))\n",
    "\n",
    "for i, k in enumerate(nn):\n",
    "    knneighb = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn6.fit(bank_train_norm, bank_target_train1)\n",
    "    \n",
    "    train[i] = knn6.score(bank_train_norm, bank_target_train1)\n",
    "    \n",
    "    test[i] = knn6.score(bank_test_norm, bank_target_test1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(nn, train, label = 'Training')\n",
    "plt.plot(nn, test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(bank_target_test1, pred_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Repeat the classification using scikit-learn's decision tree classifier (using the default parameters) and the naive Bayes (Gaussian) classifier. As above, generate the confusion matrix, classification report, and average accuracy score for each classifier. For each model, compare the average accuracry scores on the test and the training data sets. What does the comparison tell you in terms of bias-variance trade-off?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import neighbors, tree, naive_bayes\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bank_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bank_dum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bank_train, bank_test, bank_target_train, bank_target_test = train_test_split(bank_dum, bank_target, test_size=0.2, random_state=33)\n",
    "print bank_test.shape\n",
    "bank_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dectree = tree.DecisionTreeClassifier(criterion='entropy', min_samples_split=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dectree = dectree.fit(bank_train, bank_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtpred_test = dectree.predict(bank_test)\n",
    "print dtpred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print dectree.score(bank_test, bank_target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print dectree.score(bank_train, bank_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(bank_target_test, dtpred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bank_conf = confusion_matrix(bank_target_test, dtpred_test)\n",
    "print bank_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "%matplotlib inline\n",
    "plt.matshow(bank_conf)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayes = naive_bayes.GaussianNB()\n",
    "bayes = bayes.fit(bank_train, bank_target_train)\n",
    "bayes_predict = bayes.predict(bank_test)\n",
    "print bayes_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print bayes.score(bank_train, bank_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print bayes.score(bank_test, bank_target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The decision tree showed the most accuracy here with 99% on the training data and 84% on the test data. This does give an indication of overfitting here since the training data is quite a bit more accurate than the test data. More investigation and possible pruning would be needed for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:\\Users\\James Cooper\\Desktop\\DePaul\\Programming Machine Learning\\Assignment2')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  *Preprocessing and data analysis:*\n",
    "\n",
    "Examine the data for missing values. In case of categorical attributes, remove instances with missing values. In the case of numeric attributes, impute and fill-in the missing values using the attribute mean.\n",
    "\n",
    "Examine the characteristics of the attributes, including relevant statistics for each attribute, histograms illustrating the distribtions of numeric attributes, bar graphs showing value counts for categorical attributes, etc.\n",
    "\n",
    "Perform the following cross-tabulations (including generating bar charts): education+race, work-class+income, work-class+race, and race+income. In the latter case (race+income) also create a table or chart showing percentages of each race category that fall in the low-income group. Discuss your observations from this analysis.\n",
    "\n",
    "Compare and contrast the characteristics of the low-income and high-income categories across the different attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adult_mod = pd.read_csv('adult-modified.csv', na_values=['?'])\n",
    "adult_mod.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adult_mod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adult_mod.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adult_mod.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adult_mod.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rows where age is null\n",
    "adult_mod[adult_mod.age.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Replace age null values with the mean value\n",
    "mean_age = adult_mod.age.mean()\n",
    "adult_mod.age.fillna(mean_age, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adult_mod[adult_mod.age.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#values are now at 10000\n",
    "adult_mod.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adult_mod[adult_mod.workclass.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adult_mod.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All rows with workclass = null are now deleted\n",
    "adult_mod.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adult_mod['workclass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adult_mod['race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adult_mod['income'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adult_mod.groupby(adult_mod['workclass']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Histogram of age\n",
    "\n",
    "plt.hist(adult_mod['age'], bins=9, edgecolor='black')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Age Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Education Histogram\n",
    "\n",
    "plt.hist(adult_mod['education'], bins=6, edgecolor='black')\n",
    "plt.xlabel('Education Level')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Education Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hours per week worked\n",
    "\n",
    "plt.hist(adult_mod['hours-per-week'], bins=6, edgecolor='black')\n",
    "plt.xlabel('Hours Worked per Week')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Job Hours')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Working Class\n",
    "\n",
    "workclass_count = pd.value_counts(adult_mod['workclass'].values)\n",
    "print workclass_count\n",
    "\n",
    "workclass_count.plot.bar()\n",
    "plt.xlabel('Work Class Category')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Working Class Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Martial Status\n",
    "\n",
    "marital_count = pd.value_counts(adult_mod['marital-status'].values)\n",
    "print marital_count\n",
    "\n",
    "marital_count.plot.bar()\n",
    "plt.xlabel('Martial Status')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Married vs. Not Married')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Race\n",
    "\n",
    "race_count = pd.value_counts(adult_mod['race'].values)\n",
    "print race_count\n",
    "\n",
    "race_count.plot.bar()\n",
    "plt.xlabel('Race')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Demographic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Gender\n",
    "\n",
    "gender_count = pd.value_counts(adult_mod['sex'].values)\n",
    "print gender_count\n",
    "\n",
    "gender_count.plot.bar()\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Gender Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Income\n",
    "\n",
    "income_count = pd.value_counts(adult_mod['income'].values)\n",
    "print income_count\n",
    "\n",
    "income_count.plot.bar()\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Income Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross1 = pd.crosstab(adult_mod['education'], adult_mod['race'])\n",
    "print cross1\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 16, 12\n",
    "plt.show(cross1.plot(kind='bar', title='Education and Race'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross2 = pd.crosstab(adult_mod['workclass'], adult_mod['income'])\n",
    "print cross2\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 10,7\n",
    "plt.show(cross2.plot(kind='bar', title='Income by Workclass'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross3 = pd.crosstab(adult_mod['race'], adult_mod['workclass'])\n",
    "print cross3\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 10, 7\n",
    "plt.show(cross3.plot(kind='bar', title='Race by Workclass'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross4 = pd.crosstab(adult_mod['race'], adult_mod['income'])\n",
    "print cross4\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 10, 7\n",
    "plt.show(cross4.plot(kind='bar', title='Income vs. Race'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross5 = pd.crosstab(adult_mod['sex'], adult_mod['income'])\n",
    "print cross5\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 10, 7\n",
    "plt.show(cross5.plot(kind='bar', title='Gender vs. Income'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It is clear that the private sector dominates in income with the most people over 50K. As far as race, we see a disparity in which the caucasian population trends higher. The male population also tends to have higer income overall, but a higher proportion of those below 50K as compared to females."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### *Predictive Modeling and Model Evaluation:\n",
    "Using either Pandas or Scikit-learn, create dummy variables for the categorical attributes. Then separate the target attribute (\"income_>50K\") from the attributes used for training. [Note: you need to drop \"income_<=50K\" which is also created as a dummy variable in earlier steps).\n",
    "\n",
    "Use scikit-learn to build classifiers uisng Naive Bayes (Gaussian), decision tree (using \"entropy\" as selection criteria), and linear discriminant analysis (LDA). For each of these perform 10-fold cross-validation (using cross-validation module in scikit-learn) and report the overall average accuracy.\n",
    "\n",
    "For the decision tree model (generated on the full training data), generate a visualization of tree and submit it as a separate file (png, jpg, or pdf) or embed it in the Jupyter Notebook.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adult_mod.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adultmod_sci = adult_mod\n",
    "adultmod_sci.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adultmod_target = adultmod_sci.income\n",
    "adultmod_target.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adultmod_sci_dum = pd.get_dummies(adultmod_sci[['age', 'workclass', 'education', 'marital-status', 'race', 'sex', 'hours-per-week']])\n",
    "adultmod_sci_dum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adult_train, adult_test, adult_target_train, adult_target_test = train_test_split(adultmod_sci_dum, adultmod_target, test_size = 0.2, random_state=33)\n",
    "\n",
    "print adult_test.shape\n",
    "adult_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adultclf = tree.DecisionTreeClassifier(criterion='entropy', min_samples_split=3)\n",
    "adultclf = adultclf.fit(adult_train, adult_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adultpreds_test = adultclf.predict(adult_test)\n",
    "print adultpreds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print adultclf.score(adult_train, adult_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print adultclf.score(adult_test, adult_target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ad_bayes = naive_bayes.GaussianNB()\n",
    "ad_bayes = ad_bayes.fit(adult_train, adult_target_train)\n",
    "ad_preds_test = ad_bayes.predict(adult_test)\n",
    "print ad_preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ad_bayes.score(adult_train, adult_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ad_bayes.score(adult_test, adult_target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ad_lin = LinearDiscriminantAnalysis()\n",
    "ad_lin = ad_lin.fit(adult_train, adult_target_train)\n",
    "ad_lin_pred = ad_lin.predict(adult_test)\n",
    "print ad_lin_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ad_lin.score(adult_test, adult_target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross = cross_validation.cross_val_score(adultclf, adultmod_sci_dum, adultmod_target, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Overall Accuracy: %0.2f (+/- %0.2f)\" % (cross.mean(), cross.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_bayes = cross_validation.cross_val_score(ad_bayes, adultmod_sci_dum, adultmod_target, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Overall Accuracy: %0.2f (+/- %0.2f)\" % (cross_bayes.mean(), cross_bayes.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_lda = cross_validation.cross_val_score(ad_lin, adultmod_sci_dum, adultmod_target, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Overall Accuracy: %0.2f (+/- %0.2f)\" % (cross_lda.mean(), cross_bayes.std()*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
